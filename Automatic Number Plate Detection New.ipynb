{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUANWN3rpfC9"
   },
   "source": [
    "# 0. Setup of Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "146BB11JpfDA"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42hJEdo_pfDB"
   },
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet'\n",
    "CUSTOM_MODEL_NEW_NAME = 'my_ssd_mobnet_new'\n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
    "LABEL_MAP_NEW_NAME = 'label_map_new.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbPhYVy_pfDB"
   },
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow', 'scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow', 'models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace', 'annotations'),\n",
    "    'ANNOTATION_NEW_PATH': os.path.join('Tensorflow', 'workspace', 'annotationsnew'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace', 'images'),\n",
    "    'IMAGE_NEW_PATH': os.path.join('Tensorflow', 'workspace', 'imagesnew'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace', 'models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace', 'pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NAME),\n",
    "    'CHECKPOINT_NEW_PATH': os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NEW_NAME),\n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NAME, 'export'), \n",
    "    'OUTPUT_NEW_PATH': os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NEW_NAME, 'export'),\n",
    "    'TFJS_PATH': os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFJS_NEW_PATH': os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NEW_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH': os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'TFLITE_NEW_PATH': os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NEW_NAME, 'tfliteexport'),\n",
    "    'PROTOC_PATH': os.path.join('Tensorflow', 'protoc'),\n",
    "    'REALTIMEDETECTIONS_PATH': os.path.join('RealTimeDetections')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwhWZMI0pfDC"
   },
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG': os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'PIPELINE_NEW_CONFIG': os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NEW_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME),\n",
    "    'LABELMAP_NEW': os.path.join(paths['ANNOTATION_NEW_PATH'], LABEL_MAP_NEW_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HR-TfDGrpfDC"
   },
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLU-rs_ipfDE"
   },
   "source": [
    "# 1. Downloading TF Models Pretrained Models from Tensorflow Model Zoo and Installing TFOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-Cmz2edpfDE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.name=='nt':\n",
    "    !pip install wget\n",
    "    import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iA1DIq5OpfDE"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJjMHbnDs3Tv"
   },
   "outputs": [],
   "source": [
    "# Install Tensorflow Object Detection \n",
    "if os.name=='posix':  \n",
    "    !apt-get install protobuf-compiler\n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "if os.name=='nt':\n",
    "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "    wget.download(url)\n",
    "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    !cd Tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow tensorflow-gpu --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tf-models-official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "csofht2npfDE",
    "outputId": "ff5471b2-bed2-43f2-959c-327a706527b6"
   },
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5KJTnkfpfDC"
   },
   "source": [
    "# 2. Creating the Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1BVDWo7pfDC"
   },
   "outputs": [],
   "source": [
    "labels = [{'name':'licence', 'id':1}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')\n",
    "        \n",
    "with open(files['LABELMAP_NEW'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C88zyVELpfDC"
   },
   "source": [
    "# 3. Creating TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/andrewmvd/car-plate-detection?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvf5WccwrFGq",
    "outputId": "49902aeb-0bd7-4298-e1a0-5b4a64eb2064"
   },
   "outputs": [],
   "source": [
    "# IF RUNNING ON COLAB\n",
    "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
    "if os.path.exists(ARCHIVE_FILES):\n",
    "  !tar -zxvf {ARCHIVE_FILES}\n",
    "\n",
    "ARCHIVE_NEW_FILES = os.path.join(paths['IMAGE_NEW_PATH'], 'archive.zip')\n",
    "if os.path.exists(ARCHIVE_FILES):\n",
    "  !tar -zxvf {ARCHIVE_FILES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPFToGZqpfDD",
    "outputId": "0ebb456f-aadc-4a1f-96e6-fbfec1923e1c"
   },
   "outputs": [],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} \n",
    "\n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_NEW_PATH'], 'train')} -l {files['LABELMAP_NEW']} -o {os.path.join(paths['ANNOTATION_NEW_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_NEW_PATH'], 'test')} -l {files['LABELMAP_NEW']} -o {os.path.join(paths['ANNOTATION_NEW_PATH'], 'test.record')} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT4QU7pLpfDE"
   },
   "source": [
    "# 4. Copying Model Config to Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOjuTFbwpfDF"
   },
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_NEW_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_NEW_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ga8gpNslpfDF"
   },
   "source": [
    "# 5. Updating Config For Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9hRrO_ppfDF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2A0mn4ipfDF"
   },
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "config_new = config_util.get_configs_from_pipeline_file(files['PIPELINE_NEW_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vK5lotDpfDF"
   },
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()  \n",
    "    text_format.Merge(proto_str, pipeline_config)\n",
    "    \n",
    "pipeline_config_new = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_NEW_CONFIG'], \"r\") as f_new:                                                                                                                                                                                                                     \n",
    "    proto_str_new = f_new.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str_new, pipeline_config_new)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rP43Ph0JpfDG"
   },
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]\n",
    "\n",
    "pipeline_config_new.model.ssd.num_classes = len(labels)\n",
    "pipeline_config_new.train_config.batch_size = 4\n",
    "pipeline_config_new.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config_new.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config_new.train_input_reader.label_map_path= files['LABELMAP_NEW']\n",
    "pipeline_config_new.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_NEW_PATH'], 'train.record')]\n",
    "pipeline_config_new.eval_input_reader[0].label_map_path = files['LABELMAP_NEW']\n",
    "pipeline_config_new.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_NEW_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJvfgwWqpfDG"
   },
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   \n",
    "    \n",
    "config_text_new = text_format.MessageToString(pipeline_config_new)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_NEW_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zr3ON7xMpfDG"
   },
   "source": [
    "# 6. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-Y2UQmQpfDG"
   },
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMP2XDfQpfDH"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=10000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])\n",
    "command_new = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_NEW_PATH'],files['PIPELINE_NEW_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4OXXi-ApfDH",
    "outputId": "117a0e83-012b-466e-b7a6-ccaa349ac5ab"
   },
   "outputs": [],
   "source": [
    "print(command)\n",
    "print(command_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3ZsJR-qpfDH",
    "outputId": "cabec5e1-45e6-4f2f-d9cf-297d9c1d0225"
   },
   "outputs": [],
   "source": [
    "!{command}\n",
    "!{command_new}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_YRZu7npfDH"
   },
   "source": [
    "# 7. Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80L7-fdPpfDH"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])\n",
    "# command_new = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_NEW_PATH'],files['PIPELINE_NEW_CONFIG'], paths['CHECKPOINT_NEW_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lYsgEPx9pfDH",
    "outputId": "8632d48b-91d2-45d9-bcb8-c1b172bf6eed"
   },
   "outputs": [],
   "source": [
    "print(command)\n",
    "# print(command_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqTV2jGBpfDH"
   },
   "outputs": [],
   "source": [
    "!{command}\n",
    "# !{command_new}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orvRk02UpfDI"
   },
   "source": [
    "# 8. Loading Trained Model From Checkpoint and Building a Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8TYk4_oIpfDI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil\n",
    "# Prevent GPU complete consumption\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try: \n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
    "    except RunTimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDnQg-cYpfDI"
   },
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "# configs_new = config_util.get_configs_from_pipeline_file(files['PIPELINE_NEW_CONFIG'])\n",
    "# detection_model_new = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-11')).expect_partial()\n",
    "# ckpt_new = tf.compat.v2.train.Checkpoint(model=detection_model_new)\n",
    "# ckpt_new.restore(os.path.join(paths['CHECKPOINT_NEW_PATH'], 'ckpt-11')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections\n",
    "\n",
    "# @tf.function\n",
    "# def detect_fn_new(image):\n",
    "    # image, shapes = detection_model_new.preprocess(image)\n",
    "    # prediction_dict = detection_model_new.predict(image, shapes)\n",
    "    # detections = detection_model_new.postprocess(prediction_dict, shapes)\n",
    "    # return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EmsmbBZpfDI"
   },
   "source": [
    "# 9. Detecting plate from an Image, OCR, Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install avro-python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_MKiuZ4pfDI"
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBDbIhNapfDI"
   },
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])\n",
    "# category_index_new = label_map_util.create_category_index_from_labelmap(files['LABELMAP_NEW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lx3crOhOzITB"
   },
   "outputs": [],
   "source": [
    "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'TEST9.jpg')\n",
    "# IMAGE_PATH_NEW = os.path.join(paths['IMAGE_NEW_PATH'], 'Carsa.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "Tpzn1SMry1yK",
    "outputId": "c392a2c5-10fe-4fc4-9998-a1d4c7db2bd3"
   },
   "outputs": [],
   "source": [
    "img_orig = cv2.imread(IMAGE_PATH)\n",
    "# print('ORIGINAL')\n",
    "# plt.imshow(img_orig)\n",
    "# plt.show()\n",
    "img_orig_gray = cv2.cvtColor(img_orig, cv2.COLOR_BGR2GRAY)\n",
    "print('ORIGINAL')\n",
    "plt.imshow(img_orig_gray, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "img_resized = cv2.resize(img_orig, None, fx=1.2, fy=1.2, interpolation=cv2.INTER_CUBIC)\n",
    "# print('IMPROVED RESOLUTION')\n",
    "# plt.imshow(img_resized)\n",
    "# plt.show()\n",
    "\n",
    "img_detailsEnhanced = cv2.detailEnhance(img_resized, sigma_s=10, sigma_r=0.15)\n",
    "# print('DETAILS ENHANCED')\n",
    "# plt.imshow(img_detailsEnhanced)\n",
    "#plt.show()\n",
    "\n",
    "# img_BilateralFilter = cv2.bilateralFilter(img_resized, 9, 75, 75)\n",
    "# print('BILATERAL FILTER')\n",
    "# plt.imshow(img_BilateralFilter)\n",
    "# plt.show()\n",
    "img_BilateralFilterEnhanced = cv2.bilateralFilter(img_detailsEnhanced, 9, 75, 75)\n",
    "# print('BILATERAL FILTER ENHANCED')\n",
    "# plt.imshow(img_BilateralFilterEnhanced)\n",
    "# plt.show()\n",
    "\n",
    "# img_BilateralFilterGray = cv2.cvtColor(img_BilateralFilter, cv2.COLOR_BGR2GRAY)\n",
    "# print('BILATERAL GRAY')\n",
    "# plt.imshow(img_BilateralFilterGray, cmap='gray')\n",
    "# plt.show()\n",
    "img_BilateralFilterEnhancedGray = cv2.cvtColor(img_BilateralFilterEnhanced, cv2.COLOR_BGR2GRAY)\n",
    "# print('BILATERAL GRAY ENHANCED')\n",
    "# plt.imshow(img_BilateralFilterGray, cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "# img_thresh_orig = cv2.threshold(cv2.medianBlur(img_orig_gray, 3), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "# print('THRESH 1 ORIGINAL')\n",
    "# plt.imshow(img_thresh_orig, cmap='gray')\n",
    "# plt.show()\n",
    "img_threshEnhanced = cv2.threshold(cv2.medianBlur(img_BilateralFilterEnhancedGray, 3), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "print('THRESH 1 ENHANCED')\n",
    "plt.imshow(img_threshEnhanced, cmap='gray')\n",
    "plt.show()\n",
    "# img_thresh = cv2.threshold(cv2.medianBlur(img_BilateralFilterGray, 3), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "# print('THRESH 1')\n",
    "# plt.imshow(img_thresh, cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "# img_thresh_adaptive_original = cv2.adaptiveThreshold(img_orig_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "# print('THRESH 2 ORIGINAL')\n",
    "# plt.imshow(img_thresh_adaptive_original, cmap='gray')\n",
    "# plt.show()\n",
    "# img_thresh_adaptiveEnhanced = cv2.adaptiveThreshold(img_BilateralFilterEnhancedGray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "# print('THRESH 2 ENHANCED')\n",
    "# plt.imshow(img_thresh_adaptiveEnhanced, cmap='gray')\n",
    "# plt.show()\n",
    "# img_thresh_adaptive = cv2.adaptiveThreshold(img_BilateralFilterGray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "# print('THRESH 2')\n",
    "# plt.imshow(img_thresh_adaptive, cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "# img_thresh_adaptive2_original = cv2.adaptiveThreshold(img_orig_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "# print('THRESH 3 ORIGINAL')\n",
    "# plt.imshow(img_thresh_adaptive2_original, cmap='gray')\n",
    "# plt.show()\n",
    "# img_thresh_adaptive2Enhanced = cv2.adaptiveThreshold(img_BilateralFilterEnhancedGray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "# print('THRESH 3 ENHANCED')\n",
    "# plt.imshow(img_thresh_adaptive2Enhanced, cmap='gray')\n",
    "# plt.show()\n",
    "# img_thresh_adaptive2 = cv2.adaptiveThreshold(img_BilateralFilterGray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "# print('THRESH 3')\n",
    "# plt.imshow(img_thresh_adaptive2, cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "image_np = np.array(img_orig)\n",
    "# img_new = cv2.imread(IMAGE_PATH_NEW)\n",
    "# image_np_new = np.array(img_new)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "# input_tensor_new = tf.convert_to_tensor(np.expand_dims(image_np_new, 0), dtype=tf.float32)\n",
    "# detections_new = detect_fn_new(input_tensor_new)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "# num_detections_new = int(detections_new.pop('num_detections'))\n",
    "# detections_new = {key: value[0, :num_detections_new].numpy()\n",
    "              # for key, value in detections_new.items()}\n",
    "# detections_new['num_detections'] = num_detections_new\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "# detections_new['detection_classes'] = detections_new['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "# image_np_with_detections_new = image_np_new.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.8,\n",
    "            agnostic_mode=False)\n",
    "# viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "#             image_np_with_detections_new,\n",
    "#             detections_new['detection_boxes'],\n",
    "#             detections_new['detection_classes']+label_id_offset,\n",
    "#             detections_new['detection_scores'],\n",
    "#             category_index_new,\n",
    "#             use_normalized_coordinates=True,\n",
    "#             max_boxes_to_draw=5,\n",
    "#             min_score_thresh=.8,\n",
    "#             agnostic_mode=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "# plt.imshow(cv2.cvtColor(image_np_with_detections_new, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text(region, ocr_result, region_threshold):\n",
    "    rectangle_size = region.shape[0]*region.shape[1]\n",
    "    \n",
    "    plate = [] \n",
    "    for result in ocr_result:\n",
    "        length = np.sum(np.subtract(result[0][1], result[0][0]))\n",
    "        height = np.sum(np.subtract(result[0][2], result[0][1]))\n",
    "        \n",
    "        if length*height / rectangle_size > region_threshold:\n",
    "            plate.append(result[1])\n",
    "    return plate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR proccess and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_threshold = 0.7\n",
    "region_threshold = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_it(image, detections, detection_threshold, region_threshold):\n",
    "    \n",
    "    # Scores, boxes and classes above threhold\n",
    "    scores = list(filter(lambda x: x> detection_threshold, detections['detection_scores']))\n",
    "    boxes = detections['detection_boxes'][:len(scores)]\n",
    "    classes = detections['detection_classes'][:len(scores)]\n",
    "    \n",
    "    # Full image dimensions\n",
    "    width = image.shape[1]\n",
    "    height = image.shape[0]\n",
    "    \n",
    "    # Apply ROI filtering and OCR\n",
    "    for idx, box in enumerate(boxes):\n",
    "        roi = box*[height, width, height, width]\n",
    "        region = image[int(roi[0]):int(roi[2]),int(roi[1]):int(roi[3])]\n",
    "        reader = easyocr.Reader(['en'])\n",
    "        ocr_result = reader.readtext(region)\n",
    "        \n",
    "        text = filter_text(region, ocr_result, region_threshold)\n",
    "        \n",
    "        plt.imshow(cv2.cvtColor(region, cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        print(text)\n",
    "        return text, region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import uuid\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(text, region):\n",
    "    \n",
    "    now = datetime.now()\n",
    "    date_string = now.strftime('%y-%m-%d')\n",
    "    print(date_string)\n",
    "    time_string = now.strftime('%H-%M-%S')\n",
    "    print(time_string)\n",
    "    \n",
    "    folder_path_images = 'RealTimeDetectionsImages\\RealTimeDetections-{}'.format(date_string)\n",
    "    img_name = '{}_{}.jpg'.format(time_string, uuid.uuid1())\n",
    "    forlder_path_csv = 'RealTimeDetections'\n",
    "    csv_filename = 'RealTimeDetections\\RealTimeDetections-{}.csv'.format(date_string)\n",
    "    \n",
    "    if not os.path.exists(folder_path_images):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {folder_path_images}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {folder_path_images}\n",
    "    \n",
    "    if not os.path.exists(forlder_path_csv):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {forlder_path_csv}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {forlder_path_csv}\n",
    "            \n",
    "    cv2.imwrite(os.path.join(folder_path_images, img_name), region)\n",
    "                \n",
    "    with open(csv_filename, mode='a', newline='') as f:\n",
    "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        if text == []:\n",
    "            text = ['unreadable']\n",
    "        csv_writer.writerow([date_string, time_string, img_name, text])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsNAaYAo0WVL"
   },
   "source": [
    "# 10. Real Time Detections from Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_grs6OGpfDJ",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    # detections_new = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "    # num_detections_new = int(detections_new.pop('num_detections'))\n",
    "    # detections_new = {key: value[0, :num_detections_new].numpy()\n",
    "    #               for key, value in detections_new.items()}\n",
    "    # detections_new['num_detections'] = num_detections_new\n",
    "    \n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "    # detections_new['detection_classes'] = detections_new['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "    \n",
    "    img_resized = cv2.resize(image_np_with_detections, None, fx=1.2, fy=1.2, interpolation=cv2.INTER_CUBIC)\n",
    "    img_detailsEnhanced = cv2.detailEnhance(img_resized, sigma_s=10, sigma_r=0.15)\n",
    "    img_BilateralFilterEnhanced = cv2.bilateralFilter(img_detailsEnhanced, 9, 75, 75)\n",
    "    img_BilateralFilterEnhancedGray = cv2.cvtColor(img_BilateralFilterEnhanced, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.8,\n",
    "                agnostic_mode=False)\n",
    "    # viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    #             image_np_with_detections,\n",
    "    #             detections_new['detection_boxes'],\n",
    "    #             detections_new['detection_classes']+label_id_offset,\n",
    "    #             detections_new['detection_scores'],\n",
    "    #             category_index_new,\n",
    "    #             use_normalized_coordinates=True,\n",
    "    #             max_boxes_to_draw=5,\n",
    "    #             min_score_thresh=.8,\n",
    "    #             agnostic_mode=False)\n",
    "    \n",
    "    try:\n",
    "        text, region = ocr_it(image_np_with_detections, detections, detection_threshold, region_threshold)\n",
    "        # text, region = ocr_it(image_np_with_detections_new, detections_new, detection_threshold, region_threshold)\n",
    "        save_results(text, region)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzlM4jt0pfDJ"
   },
   "source": [
    "# 10. Freezing the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4olHB2npfDJ"
   },
   "outputs": [],
   "source": [
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AjO93QDpfDJ"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])\n",
    "# command_new = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_NEW_CONFIG'], paths['CHECKPOINT_NEW_PATH'], paths['OUTPUT_NEW_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6Lsp3tCpfDJ",
    "outputId": "c3828529-bf06-4df5-d7f3-145890ec3edd"
   },
   "outputs": [],
   "source": [
    "print(command)\n",
    "# print(command_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Sw1ULgHpfDJ",
    "outputId": "6fd441e1-9fc9-4889-d072-3395c21e40b6"
   },
   "outputs": [],
   "source": [
    "!{command}\n",
    "# !{command_new}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTPmdqaXpfDK"
   },
   "source": [
    "# 11. Conversion to TFJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZ6UzY_fpfDK",
    "outputId": "0c84722e-1c2b-4002-d857-80827ade828a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0oxbVynHpfDK"
   },
   "outputs": [],
   "source": [
    "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])\n",
    "# command_new = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_NEW_PATH'], 'saved_model'), paths['TFJS_NEW_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DB2AGNmJpfDK",
    "outputId": "fbc9f747-f511-47e8-df8f-5ea65cef0374"
   },
   "outputs": [],
   "source": [
    "print(command)\n",
    "# print(command_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7rfT4-hpfDK",
    "outputId": "532707fd-6feb-4bc6-84a3-325b5d16303c"
   },
   "outputs": [],
   "source": [
    "!{command}\n",
    "# !{command_new}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtUw73FHpfDK"
   },
   "source": [
    "# 12. Conversion to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XviMtewLpfDK"
   },
   "outputs": [],
   "source": [
    "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "us86cjC4pfDL"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])\n",
    "# command_new = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_NEW_CONFIG'], paths['CHECKPOINT_NEW_PATH'], paths['TFLITE_NEW_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1r5YO3rpfDL",
    "outputId": "5fcdf7a4-eee2-4365-f1ca-1751968379ea"
   },
   "outputs": [],
   "source": [
    "print(command)\n",
    "# print(command_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-xWpHN8pfDL",
    "outputId": "7f6bacd8-d077-43b5-c131-5b081fba24a4"
   },
   "outputs": [],
   "source": [
    "!{command}\n",
    "# !{command_new}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJfYMbN6pfDL"
   },
   "outputs": [],
   "source": [
    "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
    "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')\n",
    "\n",
    "# FROZEN_TFLITE_PATH_NEW = os.path.join(paths['TFLITE_NEW_PATH'], 'saved_model')\n",
    "# TFLITE_MODEL_NEW = os.path.join(paths['TFLITE_NEW_PATH'], 'saved_model', 'detect.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tflite_convert \\\n",
    "--saved_model_dir={} \\\n",
    "--output_file={} \\\n",
    "--input_shapes=1,300,300,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=FLOAT \\\n",
    "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )\n",
    "\n",
    "# command_new = \"tflite_convert \\\n",
    "# --saved_model_dir={} \\\n",
    "# --output_file={} \\\n",
    "# --input_shapes=1,300,300,3 \\\n",
    "# --input_arrays=normalized_input_image_tensor \\\n",
    "# --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "# --inference_type=FLOAT \\\n",
    "# --allow_custom_ops\".format(FROZEN_TFLITE_PATH_NEW, TFLITE_MODEL_NEW, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8GwUeoFpfDL",
    "outputId": "fac43ea4-cc85-471b-a362-e994b06fd583"
   },
   "outputs": [],
   "source": [
    "print(command)\n",
    "# print(command_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nbd7gqHMpfDL",
    "outputId": "7c8fe6d5-2415-4641-8548-39d425c202f7"
   },
   "outputs": [],
   "source": [
    "!{command}\n",
    "# !{command_new}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NQqZRdA21Uc"
   },
   "source": [
    "# 13. Zipping and Exporting Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTVTGCQp2ZJJ"
   },
   "outputs": [],
   "source": [
    "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}\n",
    "# !tar -czf models.tar.gz {path['CHECKPOINT_NEW_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "whShhB0x3PYJ",
    "outputId": "b773201d-35c9-46a8-b893-4a76bd4d5d97"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromCsv(elem):\n",
    "    \n",
    "    dataDate = pd.read_csv(os.path.join('RealTimeDetections', elem), header=None, usecols=[0])\n",
    "    dataTime = pd.read_csv(os.path.join('RealTimeDetections', elem), header=None, usecols=[1])\n",
    "    dataFileName = pd.read_csv(os.path.join('RealTimeDetections', elem), header=None, usecols=[2])\n",
    "    dataPlate = pd.read_csv(os.path.join('RealTimeDetections', elem), header=None, usecols=[3])\n",
    "    \n",
    "    listDate = dataDate.values.tolist()\n",
    "    listTime = dataTime.values.tolist()\n",
    "    listFileName = dataFileName.values.tolist()\n",
    "    listPlate = dataPlate.values.tolist()\n",
    "    \n",
    "    listDateNew = [elem[0] for elem in listDate]\n",
    "    listTimeNew = [elem[0] for elem in listTime]\n",
    "    listFileNameNew = [elem[0] for elem in listFileName]\n",
    "    listPlateNew = [elem[0] for elem in listPlate]\n",
    "    \n",
    "    listPlateNewNew = []\n",
    "    for elem in listPlateNew:\n",
    "        elem = elem[2:-2]\n",
    "        listPlateNewNew.append(elem)\n",
    "     \n",
    "    # print(listDateNew)\n",
    "    # print()\n",
    "    # print(listTimeNew)\n",
    "    # print()\n",
    "    # print(listFileNameNew)\n",
    "    # print()\n",
    "    # print(listPlateNewNew)\n",
    "    # print()\n",
    "    \n",
    "    return [listDateNew, listTimeNew, listFileNameNew, listPlateNew]\n",
    "\n",
    "csvfiles = [f for f in listdir('RealTimeDetections') if isfile(join('RealTimeDetections', f))]\n",
    "csvfiles = csvfiles[1:]\n",
    "\n",
    "returns = []\n",
    "for elem in csvfiles:\n",
    "    [listDateReturn, listTimeReturn, listFileNameReturn, listPlateReturn] = getDataFromCsv(elem)\n",
    "    returns.append([listDateReturn, listTimeReturn, listFileNameReturn, listPlateReturn])\n",
    "    \n",
    "for elem in returns:\n",
    "    print(elem)\n",
    "    print()\n",
    "    \n",
    "for elem in returns:\n",
    "    platesToPass = elem[3]\n",
    "    datesToPass = elem[0]\n",
    "    timestampsToPass = elem[1]\n",
    "    filenamesToPass = elem[2]\n",
    "    \n",
    "    timestampsValids = []\n",
    "    for i, timestampi in enumerate(timestampsToPass):\n",
    "        timestampsValid = []\n",
    "        timestamp1 = (datetime.strptime(timestampi,\"%H-%M-%S\").time())\n",
    "        \n",
    "        flag = True\n",
    "        if(len(timestampsValids) != 0):\n",
    "            for elem in timestampsValids:\n",
    "                if timestamp1.strftime(\"%H-%M-%S\") in elem:\n",
    "                    flag = False\n",
    "                    break\n",
    "        \n",
    "        if(timestampi != timestampsToPass[-1] and flag == True):\n",
    "            for j, timestampj in enumerate(timestampsToPass[i+1:]):\n",
    "                timestamp2 = (datetime.strptime(timestampj,\"%H-%M-%S\").time())\n",
    "                print(f'{timestamp1}, {timestamp2}')\n",
    "                if((timestamp1.hour == timestamp2.hour) and (timestamp1.minute == timestamp2.minute)):\n",
    "                    if(timestamp1 not in timestampsValid):\n",
    "                        timestampsValid.append(timestamp1.strftime(\"%H-%M-%S\"))\n",
    "                    if timestamp2 not in timestampsValid:\n",
    "                        timestampsValid.append(timestamp2.strftime(\"%H-%M-%S\"))\n",
    "                    print('yes')\n",
    "                else:\n",
    "                    print('no')\n",
    "                    break\n",
    "        if(len(timestampsValid) != 0):\n",
    "            timestampsValids.append(timestampsValid)\n",
    "    print(timestampsValids)\n",
    "    print()\n",
    "    \n",
    "# verificat, inlaturat alea goale, facut restul litelor pentru data placuta bla bla, merge doar cu un element?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platesList1 = ['BLO65LBF', 'BLe654BP', 'unreadable', 'BLO654BP', 'BLO654BP', 'BLO6SLBP', 'BLO654BP', 'BLe654BP', 'BLe654BP', 'BLO654BP', 'BL265-ER', 'BLO654BP', 'BLO654BP', 'BLe654BP', 'BLP654BP', 'BLO654BP', 'BLP64BP']\n",
    "platesList2 = ['MHIZDE1433', 'MHIZDE1433', 'MHIZDE1433', 'MHIZDE1433', 'MAIZ DE1433', 'MHI2 DE143', 'MHI2DE1433', 'MHIZ DE4433', 'MH12 DE 1432', 'MHIZ DE1433', 'HH12 DE1433', 'MHIZDE1433', 'HHIZDE1433']\n",
    "platesList3 = ['SA0335CC', 'SA0335C0', 'FSA0335cq', 'SAv335c0', 'S133c0', 'SA0335C0']\n",
    "platesList4 = ['0vooqu', 'Teooodz', 'Ie000dz', 'IVeoooo7', 'Tao000z', 'TVvoooo7', '1Vv00007', 'Vvoooo7', 'Vooodz', 'TVv00007', 'T9ooodz', 'Tvoooo7', 'T900dz']\n",
    "platesList5 = ['ORU', 'BO1RU', 'BOIRU', 'BOE', 'TO1RU', 'B OIERU', 'TTERU', 'B OIERU']\n",
    "platesList6 = ['8 007 BMW', '8 007 BMW', '8 007 BMW', 'B 007 BMW']\n",
    "\n",
    "\n",
    "def processPlate(stringsUnreadable, dates, timestamps, filenames):\n",
    "    \n",
    "    print(f'Placute neprocesate:\\n{stringsUnreadable}\\n')\n",
    "    \n",
    "    strings = []\n",
    "    for index, elem in enumerate(stringsUnreadable):\n",
    "        if elem != \"['unreadable']\":\n",
    "            strings.append(elem)\n",
    "    \n",
    "    counts_unreadable = []\n",
    "    for elem in strings:\n",
    "        counts_unreadable.append(strings.count(elem))\n",
    "    maximum_unreadable = max(counts_unreadable)\n",
    "    if(maximum_unreadable != \"['unreadable']\"):\n",
    "        maximum_index_unreadable = counts_unreadable.index(maximum_unreadable)\n",
    "        dateKept = dates[maximum_index_unreadable]\n",
    "        timestampKept = timestamps[maximum_index_unreadable]\n",
    "        filenameKept = filenames[maximum_index_unreadable]\n",
    "    else:\n",
    "        maximum_index_unreadable = random.randrange(0, len(count_unreadable))\n",
    "        dateKept = dates[maximum_index_unreadable]\n",
    "        timestampKept = timestamps[maximum_index_unreadable]\n",
    "        filenameKept = filenames[maximum_index_unreadable]\n",
    "    \n",
    "    print(f'Numar de placute: {len(strings)}\\n')\n",
    "    print(f'Placute:\\n{strings}\\n')\n",
    "\n",
    "    strings_sorted = strings\n",
    "    strings_sorted.sort()\n",
    "    print(f'Placute sortate:\\n{strings_sorted}\\n')\n",
    "\n",
    "    strings_unique = set(strings)\n",
    "    strings_unique = list(strings_unique)\n",
    "    print(f'Placute fara dubluri:\\n{strings_unique}\\n')\n",
    "\n",
    "    counts = []\n",
    "    for elem in strings_unique:\n",
    "        counts.append(strings.count(elem))\n",
    "    print(f'Numar de aparitii fiecare placuta unica:\\n{counts}\\n')\n",
    "\n",
    "    maximum = max(counts)\n",
    "    maximum_index = counts.index(maximum)\n",
    "    print(f'Cel mai mare numar de aparitii: {maximum}')\n",
    "    print(f'Se afla la indexul: {maximum_index}\\n')\n",
    "\n",
    "    stringsValues = []\n",
    "    stringsCounts = []\n",
    "    if(counts.count(maximum) == 1):\n",
    "        for index, elem in enumerate(strings_unique):\n",
    "            if (len(elem) == len(strings_unique[maximum_index])):\n",
    "                stringsValues.append(elem)\n",
    "                stringsCounts.append(counts[index])\n",
    "            else:\n",
    "                print(f'{elem} stearsa din detectii!')\n",
    "    elif(counts.count(maximum) == len(strings_unique)):\n",
    "        for index, elem in enumerate(strings_unique):\n",
    "            if (len(elem) == len(strings_unique[0])):\n",
    "                stringsValues.append(elem)\n",
    "                stringsCounts.append(counts[index])\n",
    "    else:\n",
    "        for index, elem in enumerate(strings_unique):\n",
    "            if (len(elem) == len(strings_unique[maximum_index])):\n",
    "                stringsValues.append(elem)\n",
    "                stringsCounts.append(counts[index])\n",
    "\n",
    "    print(f'\\nPlacute luate in considerare:\\n{stringsValues}')\n",
    "    print(f'Cu numerele de apartii:\\n{stringsCounts}\\n')\n",
    "\n",
    "    literePosibilePlacuta = []\n",
    "    factoriPlacuta = []\n",
    "    for i in range(0, len(strings_unique[maximum_index])):\n",
    "        literePosibile = []\n",
    "        factori = []\n",
    "        for index, elem in enumerate(stringsValues):\n",
    "            print(f'Litera de pe indexul {i} din placuta cu numarul {index} este {elem[i]} si are un factor de {stringsCounts[index]}')\n",
    "            literaPosibila = elem[i]\n",
    "            factor = counts[index]\n",
    "            if literaPosibila not in literePosibile:\n",
    "                literePosibile.append(literaPosibila)\n",
    "                factori.append(factor)\n",
    "            else:\n",
    "                indexLiteraExistenta = literePosibile.index(literaPosibila)\n",
    "                factori[indexLiteraExistenta] += factor\n",
    "        print()\n",
    "        literePosibilePlacuta.append(literePosibile)\n",
    "        factoriPlacuta.append(factori)\n",
    "\n",
    "    for i in range(0, len(strings_unique[maximum_index])):\n",
    "        print(f'Pentru caracterul de pe indexul {i} luam in considerare: {literePosibilePlacuta[i]} cu factorii {factoriPlacuta[i]}')\n",
    "    print()\n",
    "\n",
    "    stringFinal = ''\n",
    "    for index, elem in enumerate(literePosibilePlacuta):\n",
    "        if(len(elem) == 1):\n",
    "            print(f'Pentru indexul {index} am ales {elem[0]}')\n",
    "            stringFinal = stringFinal + elem[0]\n",
    "        else:\n",
    "            maximum_local = max(factoriPlacuta[index])\n",
    "            maximum_local_index = factoriPlacuta[index].index(maximum_local)\n",
    "            print(f'Pentru indexul {index} am ales {elem[maximum_local_index]}')\n",
    "            stringFinal = stringFinal + elem[maximum_local_index]\n",
    "\n",
    "    print(f'\\nPlacuta finala: {stringFinal}')\n",
    "    print(f'\\nPreluata la data de: {dateKept}')\n",
    "    print(f'\\nOra: {timestampKept}')\n",
    "    print(f'\\nFisierul: {filenameKept}')\n",
    "    return(stringFinal)\n",
    "\n",
    "# sa le scoata din acelasi minut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3. Training and Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "licenta",
   "language": "python",
   "name": "licenta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
