{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUANWN3rpfC9"
   },
   "source": [
    "# 0. Setup of Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "146BB11JpfDA"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42hJEdo_pfDB"
   },
   "outputs": [],
   "source": [
    "# File name, links that will be used frequently\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet'\n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbPhYVy_pfDB"
   },
   "outputs": [],
   "source": [
    "# Paths that will be used frequently\n",
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow', 'scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow', 'models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace', 'annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace', 'images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace', 'models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace', 'pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NAME),\n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH': os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NAME, 'tfjsexport'),  \n",
    "    'TFLITE_PATH': os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH': os.path.join('Tensorflow', 'protoc'),\n",
    "    'REALTIMEDETECTIONS_PATH': os.path.join('RealTimeDetections')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwhWZMI0pfDC"
   },
   "outputs": [],
   "source": [
    "# Files that will be used frequently\n",
    "files = {\n",
    "    'PIPELINE_CONFIG': os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HR-TfDGrpfDC"
   },
   "outputs": [],
   "source": [
    "# Creating all needed directories\n",
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLU-rs_ipfDE"
   },
   "source": [
    "# 1. Downloading TF Models Pretrained Models from Tensorflow Model Zoo and Installing TFOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow for Windows\n",
    "# https://www.tensorflow.org/install/source_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-Cmz2edpfDE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Installing Wget for windows users\n",
    "if os.name=='nt':\n",
    "    !pip install wget\n",
    "    import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iA1DIq5OpfDE"
   },
   "outputs": [],
   "source": [
    "# Cloning into the Tensorflow repository to get TFOD\n",
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJjMHbnDs3Tv"
   },
   "outputs": [],
   "source": [
    "# Installing Tensorflow Object Detection \n",
    "if os.name=='posix':  \n",
    "    !apt-get install protobuf-compiler\n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "if os.name=='nt':\n",
    "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "    wget.download(url)\n",
    "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    !cd Tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verification script from Tensorflow \n",
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verifying installation for TFOD\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing some other needed dependencies\n",
    "!pip install tensorflow tensorflow-gpu --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tf-models-official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverifying installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "csofht2npfDE",
    "outputId": "ff5471b2-bed2-43f2-959c-327a706527b6"
   },
   "outputs": [],
   "source": [
    "# Downloading and unzipping pretrained model\n",
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5KJTnkfpfDC"
   },
   "source": [
    "# 2. Creating the Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1BVDWo7pfDC"
   },
   "outputs": [],
   "source": [
    "# Creating the Label Map\n",
    "labels = [{'name':'licence', 'id':1}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C88zyVELpfDC"
   },
   "source": [
    "# 3. Creating TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading dataset from\n",
    "# https://www.kaggle.com/datasets/andrewmvd/car-plate-detection?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvf5WccwrFGq",
    "outputId": "49902aeb-0bd7-4298-e1a0-5b4a64eb2064"
   },
   "outputs": [],
   "source": [
    "# If running on colab, run this instruction\n",
    "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
    "if os.path.exists(ARCHIVE_FILES):\n",
    "  !tar -zxvf {ARCHIVE_FILES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloning script to generate TF records\n",
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPFToGZqpfDD",
    "outputId": "0ebb456f-aadc-4a1f-96e6-fbfec1923e1c"
   },
   "outputs": [],
   "source": [
    "# Creating TF records\n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT4QU7pLpfDE"
   },
   "source": [
    "# 4. Copying Model Config to Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOjuTFbwpfDF"
   },
   "outputs": [],
   "source": [
    "# Copying model config file to training folder\n",
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ga8gpNslpfDF"
   },
   "source": [
    "# 5. Updating Config For Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9hRrO_ppfDF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2A0mn4ipfDF"
   },
   "outputs": [],
   "source": [
    "# Getting configs from pipeline config file\n",
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vK5lotDpfDF"
   },
   "outputs": [],
   "source": [
    "# Read contents of pipeline config file\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()  \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rP43Ph0JpfDG"
   },
   "outputs": [],
   "source": [
    "# Update config file for transfer learning\n",
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJvfgwWqpfDG"
   },
   "outputs": [],
   "source": [
    "# Write updated configs to pipeline config file\n",
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zr3ON7xMpfDG"
   },
   "source": [
    "# 6. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-Y2UQmQpfDG"
   },
   "outputs": [],
   "source": [
    "# Training script from TFOD\n",
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMP2XDfQpfDH"
   },
   "outputs": [],
   "source": [
    "# Generating training command\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=10000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4OXXi-ApfDH",
    "outputId": "117a0e83-012b-466e-b7a6-ccaa349ac5ab"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing needed dependency for training\n",
    "!pip install lvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3ZsJR-qpfDH",
    "outputId": "cabec5e1-45e6-4f2f-d9cf-297d9c1d0225"
   },
   "outputs": [],
   "source": [
    "# Running training process\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_YRZu7npfDH"
   },
   "source": [
    "# 7. Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80L7-fdPpfDH"
   },
   "outputs": [],
   "source": [
    "# Generating model evaluation command\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lYsgEPx9pfDH",
    "outputId": "8632d48b-91d2-45d9-bcb8-c1b172bf6eed"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqTV2jGBpfDH"
   },
   "outputs": [],
   "source": [
    "# Running evaluating process\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orvRk02UpfDI"
   },
   "source": [
    "# 8. Loading Trained Model From Checkpoint and Building a Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8TYk4_oIpfDI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing dependency for GPU consumption\n",
    "!pip install GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preventing GPU from complete consumption of resources\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try: \n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
    "    except RunTimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDnQg-cYpfDI"
   },
   "outputs": [],
   "source": [
    "# Loading pipeline config file\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restoring latest checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-11')).expect_partial()\n",
    "\n",
    "\n",
    "# Building a detection model\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    \"\"\"Build detection model function\n",
    "\n",
    "        Parameters:\n",
    "            image ():\n",
    "\n",
    "        Returns:\n",
    "            detections (): \"\"\"\n",
    "    \n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EmsmbBZpfDI"
   },
   "source": [
    "# 9. Detecting plate from an Image, OCR, Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing needed dependencies detection\n",
    "!pip install avro-python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_MKiuZ4pfDI"
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBDbIhNapfDI"
   },
   "outputs": [],
   "source": [
    "# Categories extracted from labelmap\n",
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lx3crOhOzITB"
   },
   "outputs": [],
   "source": [
    "# Image to detect plate number from\n",
    "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'Cars1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "Tpzn1SMry1yK",
    "outputId": "c392a2c5-10fe-4fc4-9998-a1d4c7db2bd3"
   },
   "outputs": [],
   "source": [
    "# Preprocessing image\n",
    "img_orig = cv2.imread(IMAGE_PATH)\n",
    "print('ORIGINAL')\n",
    "plt.imshow(img_orig)\n",
    "plt.show()\n",
    "\n",
    "img_resized = cv2.resize(img_orig, None, fx=1.2, fy=1.2, interpolation=cv2.INTER_CUBIC)\n",
    "print('IMPROVED RESOLUTION')\n",
    "plt.imshow(img_resized)\n",
    "plt.show()\n",
    "\n",
    "img_detailsEnhanced = cv2.detailEnhance(img_resized, sigma_s=10, sigma_r=0.15)\n",
    "print('DETAILS ENHANCED')\n",
    "plt.imshow(img_detailsEnhanced)\n",
    "plt.show()\n",
    "\n",
    "img_BilateralFilterEnhanced = cv2.bilateralFilter(img_detailsEnhanced, 9, 75, 75)\n",
    "print('BILATERAL FILTER ENHANCED')\n",
    "plt.imshow(img_BilateralFilterEnhanced)\n",
    "plt.show()\n",
    "\n",
    "img_BilateralFilterEnhancedGray = cv2.cvtColor(img_BilateralFilterEnhanced, cv2.COLOR_BGR2GRAY)\n",
    "print('BILATERAL GRAY ENHANCED')\n",
    "plt.imshow(img_BilateralFilterEnhancedGray, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "img_threshEnhanced = cv2.threshold(cv2.medianBlur(img_BilateralFilterEnhancedGray, 3), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "print('THRESH 1 ENHANCED')\n",
    "plt.imshow(img_threshEnhanced, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "img_backtorgb = cv2.cvtColor(img_threshEnhanced,cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "image_np = np.array(img_backtorgb)\n",
    "\n",
    "# Detection\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# Detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "# Visualizing detection\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.8,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "print('Detected plate')\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing EasyOCR and needed dependencies\n",
    "!pip install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter OCR function\n",
    "def filter_text(region, ocr_result, region_threshold) -> list:\n",
    "    \"\"\"Filter OCR function\n",
    "\n",
    "        Parameters:\n",
    "            region ():\n",
    "            ocr_resultb ():\n",
    "            region_threshold ():\n",
    "\n",
    "        Returns:\n",
    "            plate (list): \"\"\"\n",
    "    \n",
    "    rectangle_size = region.shape[0]*region.shape[1]\n",
    "    \n",
    "    plate = [] \n",
    "    for result in ocr_result:\n",
    "        length = np.sum(np.subtract(result[0][1], result[0][0]))\n",
    "        height = np.sum(np.subtract(result[0][2], result[0][1]))\n",
    "        \n",
    "        if length*height / rectangle_size > region_threshold:\n",
    "            plate.append(result[1])\n",
    "    return plate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR proccess and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholds for detection and OCR filtering\n",
    "detection_threshold = 0.7\n",
    "region_threshold = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR function\n",
    "def ocr_it(image, detections, detection_threshold, region_threshold):\n",
    "    \"\"\"OCR function\n",
    "\n",
    "        Parameters:\n",
    "            image ():\n",
    "            detections ():\n",
    "            detection_threshold ():\n",
    "            region_threshold ():\n",
    "\n",
    "        Returns:\n",
    "            text (): \n",
    "            region (): \"\"\"\n",
    "    \n",
    "    # Scores, boxes and classes above threhold\n",
    "    scores = list(filter(lambda x: x> detection_threshold, detections['detection_scores']))\n",
    "    boxes = detections['detection_boxes'][:len(scores)]\n",
    "    classes = detections['detection_classes'][:len(scores)]\n",
    "    \n",
    "    # Full image dimensions\n",
    "    width = image.shape[1]\n",
    "    height = image.shape[0]\n",
    "    \n",
    "    # Apply ROI filtering and OCR\n",
    "    for idx, box in enumerate(boxes):\n",
    "        roi = box*[height, width, height, width]\n",
    "        region = image[int(roi[0]):int(roi[2]),int(roi[1]):int(roi[3])]\n",
    "        reader = easyocr.Reader(['en'])\n",
    "        ocr_result = reader.readtext(region)\n",
    "        \n",
    "        text = filter_text(region, ocr_result, region_threshold)\n",
    "        \n",
    "        plt.imshow(cv2.cvtColor(region, cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        print(text)\n",
    "        return text, region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import uuid\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving detections\n",
    "def save_results(text, region):\n",
    "    \"\"\"Save results function\n",
    "\n",
    "        Parameters:\n",
    "            text ():\n",
    "            region ():\n",
    "\n",
    "        Returns: N/A\"\"\"\n",
    "    \n",
    "    now = datetime.now()\n",
    "    date_string = now.strftime('%y-%m-%d')\n",
    "    print(date_string)\n",
    "    time_string = now.strftime('%H-%M-%S')\n",
    "    print(time_string)\n",
    "    \n",
    "    folder_path_images = 'RealTimeDetectionsImages\\RealTimeDetections-{}'.format(date_string)\n",
    "    img_name = '{}_{}.jpg'.format(time_string, uuid.uuid1())\n",
    "    forlder_path_csv = 'RealTimeDetections'\n",
    "    csv_filename = 'RealTimeDetections\\RealTimeDetections-{}.csv'.format(date_string)\n",
    "    \n",
    "    if not os.path.exists(folder_path_images):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {folder_path_images}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {folder_path_images}\n",
    "    \n",
    "    if not os.path.exists(forlder_path_csv):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {forlder_path_csv}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {forlder_path_csv}\n",
    "            \n",
    "    cv2.imwrite(os.path.join(folder_path_images, img_name), region)\n",
    "                \n",
    "    with open(csv_filename, mode='a', newline='') as f:\n",
    "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        if text == []:\n",
    "            text = ['unreadable']\n",
    "        csv_writer.writerow([date_string, time_string, img_name, text])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsNAaYAo0WVL"
   },
   "source": [
    "# 10. Real Time Detections from Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_grs6OGpfDJ",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Real Time Detections from Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Preprocessing image\n",
    "    img_resized = cv2.resize(frame, None, fx=1.2, fy=1.2, interpolation=cv2.INTER_CUBIC)\n",
    "    img_detailsEnhanced = cv2.detailEnhance(img_resized, sigma_s=10, sigma_r=0.15)\n",
    "    img_BilateralFilterEnhanced = cv2.bilateralFilter(img_detailsEnhanced, 9, 75, 75)\n",
    "    img_BilateralFilterEnhancedGray = cv2.cvtColor(img_BilateralFilterEnhanced, cv2.COLOR_BGR2GRAY)\n",
    "    img_threshEnhanced = cv2.threshold(cv2.medianBlur(img_BilateralFilterEnhancedGray, 3), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "    img_backtorgb = cv2.cvtColor(img_threshEnhanced,cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    image_np = np.array(frame)\n",
    "    image_np_preprocessed = np.array(img_backtorgb)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np_preprocessed, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "    \n",
    "    # Detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.8,\n",
    "                agnostic_mode=False)\n",
    "    \n",
    "    try:\n",
    "        text, region = ocr_it(image_np_with_detections, detections, detection_threshold, region_threshold)\n",
    "        save_results(text, region)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Getting and processing data from the CSV detection files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromCsv(elem):\n",
    "    \"\"\"Get data from CSV function\n",
    "\n",
    "        Parameters:\n",
    "            elem ():\n",
    "\n",
    "        Returns: \n",
    "        [listDateNew, listTimeNew, listFileNameNew, listPlateNew] (): \"\"\"\n",
    "    \n",
    "    \n",
    "    dataDate = pd.read_csv(os.path.join('RealTimeDetections', elem), header=None, usecols=[0])\n",
    "    dataTime = pd.read_csv(os.path.join('RealTimeDetections', elem), header=None, usecols=[1])\n",
    "    dataFileName = pd.read_csv(os.path.join('RealTimeDetections', elem), header=None, usecols=[2])\n",
    "    dataPlate = pd.read_csv(os.path.join('RealTimeDetections', elem), header=None, usecols=[3])\n",
    "    \n",
    "    listDate = dataDate.values.tolist()\n",
    "    listTime = dataTime.values.tolist()\n",
    "    listFileName = dataFileName.values.tolist()\n",
    "    listPlate = dataPlate.values.tolist()\n",
    "    \n",
    "    listDateNew = [elem[0] for elem in listDate]\n",
    "    listTimeNew = [elem[0] for elem in listTime]\n",
    "    listFileNameNew = [elem[0] for elem in listFileName]\n",
    "    listPlateNew = [elem[0] for elem in listPlate]\n",
    "    \n",
    "    listPlateNewNew = []\n",
    "    for elem in listPlateNew:\n",
    "        elem = elem[2:-2]\n",
    "        listPlateNewNew.append(elem)\n",
    "     \n",
    "    # print(listDateNew)\n",
    "    # print()\n",
    "    # print(listTimeNew)\n",
    "    # print()\n",
    "    # print(listFileNameNew)\n",
    "    # print()\n",
    "    # print(listPlateNewNew)\n",
    "    # print()\n",
    "    # print(\"--------------------------------------------------------\")\n",
    "    \n",
    "    return [listDateNew, listTimeNew, listFileNameNew, listPlateNew]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redundancyFunction(datesToPass, timestampsToPass, filenamesToPass, platesToPass):    \n",
    "    \"\"\"Build detection model function\n",
    "        Parameters:\n",
    "            datesToPass ():\n",
    "            timestampsToPass ():\n",
    "            filenamesToPass ():\n",
    "            platesToPass ():\n",
    "        Returns:\n",
    "            [timestampsValids, datesValids, filenamesValids, platesValids] (): \"\"\"\n",
    "    \n",
    "    datesValids = []\n",
    "    timestampsValids = []\n",
    "    filenamesValids = []\n",
    "    platesValids = []\n",
    "    \n",
    "    for i, timestampi in enumerate(timestampsToPass):\n",
    "        datesValid = []\n",
    "        timestampsValid = []\n",
    "        filenamesValid = []\n",
    "        platesValid = []\n",
    "        onlyOne = True\n",
    "        \n",
    "        timestamp1 = (datetime.strptime(timestampi,\"%H-%M-%S\").time())\n",
    "        \n",
    "        flag = True\n",
    "        if(len(timestampsValids) != 0):\n",
    "            for elem in timestampsValids:\n",
    "                if timestamp1.strftime(\"%H-%M-%S\") in elem:\n",
    "                    flag = False\n",
    "                    break\n",
    "        \n",
    "        if(timestampi != timestampsToPass[-1] and flag == True):\n",
    "            for j, timestampj in enumerate(timestampsToPass[i+1:]):\n",
    "                timestamp2 = (datetime.strptime(timestampj,\"%H-%M-%S\").time())\n",
    "                # print(f'{timestamp1}, {timestamp2}')\n",
    "                if((timestamp1.hour == timestamp2.hour) and (timestamp1.minute == timestamp2.minute)):\n",
    "                    if(timestamp1.strftime(\"%H-%M-%S\") not in timestampsValid):\n",
    "                        timestampsValid.append(timestamp1.strftime(\"%H-%M-%S\"))\n",
    "                        datesValid.append(datesToPass[i])\n",
    "                        filenamesValid.append(filenamesToPass[i])\n",
    "                        platesValid.append(platesToPass[i])\n",
    "                    if timestamp2 not in timestampsValid:\n",
    "                        timestampsValid.append(timestamp2.strftime(\"%H-%M-%S\"))\n",
    "                        datesValid.append(datesToPass[i+1+j])\n",
    "                        filenamesValid.append(filenamesToPass[i+1+j])\n",
    "                        platesValid.append(platesToPass[i+1+j])\n",
    "                        onlyOne = False\n",
    "                elif(onlyOne == True):\n",
    "                    timestampsValid.append(timestamp1.strftime(\"%H-%M-%S\"))\n",
    "                    datesValid.append(datesToPass[i])\n",
    "                    filenamesValid.append(filenamesToPass[i])\n",
    "                    platesValid.append(platesToPass[i])\n",
    "                    break\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        if(len(timestampsValid) != 0):\n",
    "            timestampsValids.append(timestampsValid)\n",
    "            datesValids.append(datesValid)\n",
    "            filenamesValids.append(filenamesValid)\n",
    "            platesValids.append(platesValid)\n",
    "    \n",
    "    # print(timestampsValids)\n",
    "    # print()\n",
    "    # print(datesValids)\n",
    "    # print()\n",
    "    # print(filenamesValids)\n",
    "    # print()\n",
    "    # print(platesValids)\n",
    "    # print()\n",
    "    \n",
    "    return [timestampsValids, datesValids, filenamesValids, platesValids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processPlate(stringsUnreadable, dates, timestamps, filenames):\n",
    "    \"\"\"Redundancy function\n",
    "\n",
    "        Parameters:\n",
    "            stringsUnreadable ():\n",
    "            dates ():\n",
    "            timestamps ():\n",
    "            filenames ():\n",
    "\n",
    "        Returns: \n",
    "        stringFinal (): \"\"\"\n",
    "    \n",
    "    \n",
    "    # print(f'Placute neprocesate:\\n{stringsUnreadable}\\n')\n",
    "    \n",
    "    breakFlag = False\n",
    "    \n",
    "    strings = []\n",
    "    for index, elem in enumerate(stringsUnreadable):\n",
    "        if elem != \"['unreadable']\":\n",
    "            strings.append(elem)\n",
    "    \n",
    "    counts_unreadable = []\n",
    "    for elem in stringsUnreadable:\n",
    "        counts_unreadable.append(stringsUnreadable.count(elem))\n",
    "    # print(counts_unreadable)\n",
    "    \n",
    "    maximum_unreadable = max(counts_unreadable)\n",
    "    if(maximum_unreadable != \"['unreadable']\"):\n",
    "        maximum_index_unreadable = counts_unreadable.index(maximum_unreadable)\n",
    "        dateKept = dates[maximum_index_unreadable]\n",
    "        timestampKept = timestamps[maximum_index_unreadable]\n",
    "        filenameKept = filenames[maximum_index_unreadable]\n",
    "    else:\n",
    "        maximum_index_unreadable = random.randrange(0, len(count_unreadable))\n",
    "        dateKept = dates[maximum_index_unreadable]\n",
    "        timestampKept = timestamps[maximum_index_unreadable]\n",
    "        filenameKept = filenames[maximum_index_unreadable]\n",
    "    \n",
    "    # print(f'Numar de placute: {len(strings)}\\n')\n",
    "    # print(f'Placute:\\n{strings}\\n')\n",
    "\n",
    "    strings_sorted = strings\n",
    "    strings_sorted.sort()\n",
    "    # print(f'Placute sortate:\\n{strings_sorted}\\n')\n",
    "\n",
    "    strings_unique = set(strings)\n",
    "    strings_unique = list(strings_unique)\n",
    "    # print(f'Placute fara dubluri:\\n{strings_unique}\\n')\n",
    "\n",
    "    if len(strings_unique) == 0:\n",
    "        breakFlag = True\n",
    "    \n",
    "    if breakFlag == True:\n",
    "        stringFinal = stringsUnreadable[0]\n",
    "        dateKept = dates[0]\n",
    "        timestampKept = timestamps[0]\n",
    "        filenameKept = filenames[0]\n",
    "    \n",
    "    if breakFlag == False:\n",
    "        counts = []\n",
    "        for elem in strings_unique:\n",
    "            counts.append(strings.count(elem))\n",
    "        # print(f'Numar de aparitii fiecare placuta unica:\\n{counts}\\n')\n",
    "\n",
    "        maximum = max(counts)\n",
    "        maximum_index = counts.index(maximum)\n",
    "        # print(f'Cel mai mare numar de aparitii: {maximum}')\n",
    "        # print(f'Se afla la indexul: {maximum_index}\\n')\n",
    "\n",
    "        stringsValues = []\n",
    "        stringsCounts = []\n",
    "        if(counts.count(maximum) == 1):\n",
    "            for index, elem in enumerate(strings_unique):\n",
    "                if (len(elem) == len(strings_unique[maximum_index])):\n",
    "                    stringsValues.append(elem)\n",
    "                    stringsCounts.append(counts[index])\n",
    "                else:\n",
    "                    pass\n",
    "                    # print(f'{elem} stearsa din detectii!')\n",
    "        elif(counts.count(maximum) == len(strings_unique)):\n",
    "            for index, elem in enumerate(strings_unique):\n",
    "                if (len(elem) == len(strings_unique[0])):\n",
    "                    stringsValues.append(elem)\n",
    "                    stringsCounts.append(counts[index])\n",
    "        else:\n",
    "            for index, elem in enumerate(strings_unique):\n",
    "                if (len(elem) == len(strings_unique[maximum_index])):\n",
    "                    stringsValues.append(elem)\n",
    "                    stringsCounts.append(counts[index])\n",
    "\n",
    "        # print(f'\\nPlacute luate in considerare:\\n{stringsValues}')\n",
    "        # print(f'Cu numerele de apartii:\\n{stringsCounts}\\n')\n",
    "\n",
    "        literePosibilePlacuta = []\n",
    "        factoriPlacuta = []\n",
    "        for i in range(0, len(strings_unique[maximum_index])):\n",
    "            literePosibile = []\n",
    "            factori = []\n",
    "            for index, elem in enumerate(stringsValues):\n",
    "                # print(f'Litera de pe indexul {i} din placuta cu numarul {index} este {elem[i]} si are un factor de {stringsCounts[index]}')\n",
    "                literaPosibila = elem[i]\n",
    "                factor = counts[index]\n",
    "                if literaPosibila not in literePosibile:\n",
    "                    literePosibile.append(literaPosibila)\n",
    "                    factori.append(factor)\n",
    "                else:\n",
    "                    indexLiteraExistenta = literePosibile.index(literaPosibila)\n",
    "                    factori[indexLiteraExistenta] += factor\n",
    "            # print()\n",
    "            literePosibilePlacuta.append(literePosibile)\n",
    "            factoriPlacuta.append(factori)\n",
    "\n",
    "        for i in range(0, len(strings_unique[maximum_index])):\n",
    "            pass\n",
    "            # print(f'Pentru caracterul de pe indexul {i} luam in considerare: {literePosibilePlacuta[i]} cu factorii {factoriPlacuta[i]}')\n",
    "        # print()\n",
    "\n",
    "        stringFinal = ''\n",
    "        for index, elem in enumerate(literePosibilePlacuta):\n",
    "            if(len(elem) == 1):\n",
    "                # print(f'Pentru indexul {index} am ales {elem[0]}')\n",
    "                stringFinal = stringFinal + elem[0]\n",
    "            else:\n",
    "                maximum_local = max(factoriPlacuta[index])\n",
    "                maximum_local_index = factoriPlacuta[index].index(maximum_local)\n",
    "                # print(f'Pentru indexul {index} am ales {elem[maximum_local_index]}')\n",
    "                stringFinal = stringFinal + elem[maximum_local_index]\n",
    "\n",
    "    print(f'\\nPlacuta finala: {stringFinal}')\n",
    "    # print(f'\\nPreluata la data de: {dateKept}')\n",
    "    # print(f'\\nOra: {timestampKept}')\n",
    "    # print(f'\\nFisierul: {filenameKept}')\n",
    "    # print('================================')\n",
    "    return [stringFinal, dateKept, timestampKept, filenameKept]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfiles = [f for f in listdir('RealTimeDetections') if isfile(join('RealTimeDetections', f)) and f.endswith('.csv')]\n",
    "# First one doesn't conform to the template\n",
    "# csvfiles = csvfiles[2:]\n",
    "# print(csvfiles)\n",
    "\n",
    "\n",
    "for elem in csvfiles:\n",
    "    csvReturns = []\n",
    "    redReturns = []\n",
    "    finalPlate = ''\n",
    "    \n",
    "    [csvListDateReturn, csvListTimeReturn, csvListFileNameReturn, csvListPlateReturn] = getDataFromCsv(elem)\n",
    "    csvReturns.extend([csvListDateReturn, csvListTimeReturn, csvListFileNameReturn, csvListPlateReturn])\n",
    "    \n",
    "    # print(csvReturns[0])\n",
    "    # print()\n",
    "    # print(csvReturns[1])\n",
    "    # print()\n",
    "    # print(csvReturns[2])\n",
    "    # print()\n",
    "    # print(csvReturns[3])\n",
    "    # print('---------------------------------------')\n",
    "    \n",
    "    [redListDateReturn, redListTimeReturn, redListFileNameReturn, redListPlateReturn] = redundancyFunction(csvReturns[0], csvReturns[1], csvReturns[2], csvReturns[3])\n",
    "    redReturns.extend([redListDateReturn, redListTimeReturn, redListFileNameReturn, redListPlateReturn])\n",
    "    \n",
    "    # print(redReturns[0])\n",
    "    # print()\n",
    "    # print(redReturns[1])\n",
    "    # print()\n",
    "    # print(redReturns[2])\n",
    "    # print()\n",
    "    # print(redReturns[3])\n",
    "    # print('---------------------------------------')\n",
    "    \n",
    "\n",
    "    \n",
    "    for i, platesToProc in enumerate (redReturns[3]):\n",
    "        finalPlate = processPlate(platesToProc, redReturns[1][i], redReturns[0][i], redReturns[2][i])\n",
    "        \n",
    "        f = open(join('RealTimeDetections\\\\Processed', f'Processed_{finalPlate[1]}.csv'), 'a')\n",
    "\n",
    "        # create the csv writer\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        finalPlate0 = finalPlate[0].replace(' ', '')\n",
    "        finalPlate0 = finalPlate0.upper()\n",
    "        \n",
    "        row = [finalPlate[1], finalPlate[2], finalPlate[3], finalPlate0]\n",
    "        # write a row to the csv file\n",
    "        writer.writerow(row)\n",
    "\n",
    "        # close the file\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvProcessedfiles = [f for f in listdir('RealTimeDetections\\\\Processed') if isfile(join('RealTimeDetections\\\\Processed', f)) and f.endswith('.csv')]\n",
    "\n",
    "for elem in csvProcessedfiles:\n",
    "    findIndex = elem.find('.csv')\n",
    "    elemOutput = elem[:findIndex]\n",
    "    elemOutput = elemOutput + \"_NoBlanks.csv\"\n",
    "    \n",
    "    with open(join('RealTimeDetections\\\\Processed', elem), 'r') as inputFile, open(join('RealTimeDetections\\\\NoBlanks', elemOutput), 'w', newline='') as outputFile:\n",
    "        writer = csv.writer(outputFile)\n",
    "        for row in csv.reader(inputFile):\n",
    "            if any(field.strip() for field in row):\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Send email alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import smtplib and ssl for the actual sending function\n",
    "import smtplib, ssl\n",
    "\n",
    "# Import the email modules we'll need\n",
    "from email.message import EmailMessage\n",
    "\n",
    "# To send also the date and the time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smtp_server = \"smtp.mail.yahoo.com\"\n",
    "port = 587  # For starttls\n",
    "sender = 'anprthesis@yahoo.com'\n",
    "receiver = 'anprthesis@gmail.com'\n",
    "password = 'wamxfatshsvkanyb'\n",
    "\n",
    "# Create a secure SSL context\n",
    "context = ssl.create_default_context()\n",
    "\n",
    "\n",
    "def sendAlert(followerType, followerPlate):\n",
    "    \"\"\"Send mail alerts function.\n",
    "\n",
    "    Parameters:\n",
    "        followerType ():\n",
    "        followerPlate ():\n",
    "\n",
    "    Returns: N/A\"\"\"\n",
    "\n",
    "    # Try to log in to server and send email\n",
    "    try:\n",
    "        server = smtplib.SMTP(smtp_server,port)\n",
    "        server.ehlo()\n",
    "        server.starttls(context=context) # Secure the connection\n",
    "        server.ehlo()\n",
    "        server.login(sender, password)\n",
    "        \n",
    "        emailMsg = EmailMessage()\n",
    "        \n",
    "        nowMoment = datetime.now()\n",
    "        date_string = nowMoment.strftime('%y-%m-%d')\n",
    "        time_string = nowMoment.strftime('%H-%M-%S')\n",
    "\n",
    "        msg = f'You are being followed by {followerPlate}, date {date_string}, time {time_string}.\\nType of follower: {followerType}.'\n",
    "    \n",
    "        emailMsg.set_content(msg)\n",
    "        \n",
    "        emailMsg['Subject'] = f'Dangerous car behind!'\n",
    "        emailMsg['From'] = sender\n",
    "        emailMsg['To'] = receiver\n",
    "\n",
    "        server.send_message(emailMsg)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    finally:\n",
    "        server.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Threading, Real Time Detections, Processing of Detections, Alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from time import sleep, perf_counter\n",
    "from threading import Thread\n",
    "import shutil\n",
    "\n",
    "# File cleanup\n",
    "src = 'RealTimeDetections\\\\NoBlanks'\n",
    "trg = 'RealTimeDetections\\\\ForDetections'\n",
    "deleteProcessed = 'RealTimeDetections\\\\Processed'\n",
    "deleteNoBlanks = 'RealTimeDetections\\\\NoBlanks'\n",
    "    \n",
    "sourceFiles = os.listdir(src)\n",
    "targetFiles = os.listdir(trg)\n",
    "deleteProcessedFiles = os.listdir(deleteProcessed)\n",
    "deleteNoBlanksFiles = os.listdir(deleteNoBlanks)\n",
    "\n",
    "for fname in targetFiles:\n",
    "    if (isfile(join(trg, fname)) and fname.endswith('.csv')):\n",
    "        os.remove(os.path.join(trg, fname))\n",
    "        \n",
    "# Copying files used for alerts to their correct directory\n",
    "for fname in sourceFiles:\n",
    "    shutil.copy2(os.path.join(src, fname), trg)\n",
    "    \n",
    "\n",
    "for fname in deleteNoBlanksFiles:\n",
    "    if (isfile(join(deleteNoBlanks, fname)) and fname.endswith('.csv')):\n",
    "        os.remove(os.path.join(deleteNoBlanks, fname))\n",
    "for fname in deleteProcessedFiles:\n",
    "    if (isfile(join(deleteProcessed, fname)) and fname.endswith('.csv')):\n",
    "        os.remove(os.path.join(deleteProcessed, fname)) \n",
    "\n",
    "        \n",
    "def task1():\n",
    "    \"\"\"\n",
    "    Task 1 for parallel procssing.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Computing a list of previous detections\n",
    "    csvForDetectionsfiles = [f for f in listdir('RealTimeDetections\\\\ForDetections') if isfile(join('RealTimeDetections\\\\ForDetections', f)) and f.endswith('.csv')]\n",
    "    \n",
    "    previousDetections = []\n",
    "    for elemCsvForDetections in csvForDetectionsfiles:\n",
    "    \n",
    "        detections = pd.read_csv(os.path.join('RealTimeDetections\\\\ForDetections', elemCsvForDetections), header=None, usecols=[3])\n",
    "        listDetections = detections.values.tolist()\n",
    "        listDetectionsNew = [elem[0] for elem in listDetections]\n",
    "        listDetectionsNewNew = [elem[2:-2] for elem in listDetectionsNew]\n",
    "        for elem in listDetectionsNewNew:\n",
    "            previousDetections.append(elem)\n",
    "    \n",
    "    # Real Time Detections from Webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    nowDetections = []\n",
    "    while cap.isOpened(): \n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Preprocessing image\n",
    "        img_resized = cv2.resize(frame, None, fx=1.2, fy=1.2, interpolation=cv2.INTER_CUBIC)\n",
    "        img_detailsEnhanced = cv2.detailEnhance(img_resized, sigma_s=10, sigma_r=0.15)\n",
    "        img_BilateralFilterEnhanced = cv2.bilateralFilter(img_detailsEnhanced, 9, 75, 75)\n",
    "        img_BilateralFilterEnhancedGray = cv2.cvtColor(img_BilateralFilterEnhanced, cv2.COLOR_BGR2GRAY)\n",
    "        img_threshEnhanced = cv2.threshold(cv2.medianBlur(img_BilateralFilterEnhancedGray, 3), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "        img_backtorgb = cv2.cvtColor(img_threshEnhanced,cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "        image_np = np.array(frame)\n",
    "        image_np_preprocessed = np.array(img_backtorgb)\n",
    "    \n",
    "        input_tensor = tf.convert_to_tensor(np.expand_dims(image_np_preprocessed, 0), dtype=tf.float32)\n",
    "        detections = detect_fn(input_tensor)\n",
    "    \n",
    "        num_detections = int(detections.pop('num_detections'))\n",
    "        detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "        detections['num_detections'] = num_detections\n",
    "    \n",
    "        # Detection_classes should be ints.\n",
    "        detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "        label_id_offset = 1\n",
    "        image_np_with_detections = image_np.copy()\n",
    "\n",
    "        viz_utils.visualize_boxes_and_labels_on_image_array(image_np_with_detections,detections['detection_boxes'],detections['detection_classes']+label_id_offset,detections['detection_scores'],category_index,use_normalized_coordinates=True,max_boxes_to_draw=5,min_score_thresh=.8,agnostic_mode=False)\n",
    "    \n",
    "        try:\n",
    "            text, region = ocr_it(image_np_with_detections, detections, detection_threshold, region_threshold)\n",
    "            save_results(text, region)\n",
    "            \n",
    "            toCheck = text[0]\n",
    "            toCheck = toCheck.replace(' ', '')\n",
    "            toCheck = toCheck.upper()\n",
    "            \n",
    "            # Sending alerts\n",
    "            if ((toCheck in previousDetections) or (nowDetections.count(toCheck) > 1)):\n",
    "                nowDetections.append(toCheck)\n",
    "                if ((toCheck in previousDetections) and (nowDetections.count(toCheck) > 1)):\n",
    "                    typeOfFollowing = 'detected previously and following you now'\n",
    "                    print(f'Danger, {typeOfFollowing}.')\n",
    "                    sendAlert(typeOfFollowing, toCheck)\n",
    "                elif (toCheck in previousDetections):\n",
    "                    typeOfFollowing = 'detected in a previous moment'\n",
    "                    print(f'Danger, {typeOfFollowing}.')\n",
    "                    sendAlert(typeOfFollowing, toCheck)\n",
    "                else:\n",
    "                    typeOfFollowinf = 'detected for too long in this moment'\n",
    "                    print(f'Danger, {typeOfFollowing}.')\n",
    "                    sendAlert(typeOfFollowing, toCheck)\n",
    "            else:\n",
    "                print('Safe')\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "            \n",
    "def task2():\n",
    "    \"\"\"\n",
    "    Task 2 for parallel procssing.\n",
    "    \"\"\"\n",
    "    \n",
    "    csvfiles = [f for f in listdir('RealTimeDetections') if isfile(join('RealTimeDetections', f)) and f.endswith('.csv')]\n",
    "    # First one doesn't conform to the template\n",
    "    # csvfiles = csvfiles[2:]\n",
    "    # print(csvfiles)\n",
    "\n",
    "\n",
    "    for elem in csvfiles:\n",
    "        csvReturns = []\n",
    "        redReturns = []\n",
    "        finalPlate = ''\n",
    "    \n",
    "        [csvListDateReturn, csvListTimeReturn, csvListFileNameReturn, csvListPlateReturn] = getDataFromCsv(elem)\n",
    "        csvReturns.extend([csvListDateReturn, csvListTimeReturn, csvListFileNameReturn, csvListPlateReturn])\n",
    "            \n",
    "        #print(csvReturns[0])\n",
    "        #print()\n",
    "        #print(csvReturns[1])\n",
    "        #print()\n",
    "        #print(csvReturns[2])\n",
    "        #print()\n",
    "        #print(csvReturns[3])\n",
    "        #print('---------------------------------------')\n",
    "    \n",
    "        [redListDateReturn, redListTimeReturn, redListFileNameReturn, redListPlateReturn] = redundancyFunction(csvReturns[0], csvReturns[1], csvReturns[2], csvReturns[3])\n",
    "        redReturns.extend([redListDateReturn, redListTimeReturn, redListFileNameReturn, redListPlateReturn])\n",
    "    \n",
    "        #print(redReturns[0])\n",
    "        #print()\n",
    "        #print(redReturns[1])\n",
    "        #print()\n",
    "        #print(redReturns[2])\n",
    "        #print()\n",
    "        #print(redReturns[3])\n",
    "        #print('---------------------------------------')\n",
    "    \n",
    "        for i, platesToProc in enumerate (redReturns[3]):\n",
    "            finalPlate = processPlate(platesToProc, redReturns[1][i], redReturns[0][i], redReturns[2][i])\n",
    "        \n",
    "            f = open(join('RealTimeDetections\\\\Processed', f'Processed_{finalPlate[1]}.csv'), 'a')\n",
    "\n",
    "            # create the csv writer\n",
    "            writer = csv.writer(f)\n",
    "        \n",
    "            row = [finalPlate[1], finalPlate[2], finalPlate[3], finalPlate[0]]\n",
    "            # write a row to the csv file\n",
    "            writer.writerow(row)\n",
    "\n",
    "            # close the file\n",
    "            f.close()\n",
    "        \n",
    "        csvProcessedfiles = [f for f in listdir('RealTimeDetections\\\\Processed') if isfile(join('RealTimeDetections\\\\Processed', f)) and f.endswith('.csv')]\n",
    "\n",
    "        for elem in csvProcessedfiles:\n",
    "            findIndex = elem.find('.csv')\n",
    "            elemOutput = elem[:findIndex]\n",
    "            elemOutput = elemOutput + \"_NoBlanks.csv\"\n",
    "    \n",
    "        with open(join('RealTimeDetections\\\\Processed', elem), 'r') as inputFile, open(join('RealTimeDetections\\\\NoBlanks', elemOutput), 'w', newline='') as outputFile:\n",
    "            writer = csv.writer(outputFile)\n",
    "            for row in csv.reader(inputFile):\n",
    "                if any(field.strip() for field in row):\n",
    "                    writer.writerow(row)    \n",
    "\n",
    "    \n",
    "start_time = perf_counter()\n",
    "\n",
    "# Create two new threads\n",
    "t1 = Thread(target=task1)\n",
    "t2 = Thread(target=task2)\n",
    "\n",
    "# Start the threads\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "# Wait for the threads to complete\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "end_time = perf_counter()\n",
    "\n",
    "print(f'It took {end_time- start_time: 0.2f} second(s) to complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzlM4jt0pfDJ"
   },
   "source": [
    "# 14. Freezing the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4olHB2npfDJ"
   },
   "outputs": [],
   "source": [
    "# Freeze script from TFOD\n",
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AjO93QDpfDJ"
   },
   "outputs": [],
   "source": [
    "# Generating freezing command\n",
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6Lsp3tCpfDJ",
    "outputId": "c3828529-bf06-4df5-d7f3-145890ec3edd"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Sw1ULgHpfDJ",
    "outputId": "6fd441e1-9fc9-4889-d072-3395c21e40b6"
   },
   "outputs": [],
   "source": [
    "# Running freezing process\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTPmdqaXpfDK"
   },
   "source": [
    "# 15. Conversion to TFJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZ6UzY_fpfDK",
    "outputId": "0c84722e-1c2b-4002-d857-80827ade828a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Installing needed package for conversion to TFJS\n",
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0oxbVynHpfDK"
   },
   "outputs": [],
   "source": [
    "# Generating conversion to TFJS command\n",
    "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DB2AGNmJpfDK",
    "outputId": "fbc9f747-f511-47e8-df8f-5ea65cef0374"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7rfT4-hpfDK",
    "outputId": "532707fd-6feb-4bc6-84a3-325b5d16303c"
   },
   "outputs": [],
   "source": [
    "# Running conversion to TFJS command\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtUw73FHpfDK"
   },
   "source": [
    "# 16. Conversion to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XviMtewLpfDK"
   },
   "outputs": [],
   "source": [
    "# TFLite script from TFOD\n",
    "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "us86cjC4pfDL"
   },
   "outputs": [],
   "source": [
    "# Generating conversion to TFLite command\n",
    "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1r5YO3rpfDL",
    "outputId": "5fcdf7a4-eee2-4365-f1ca-1751968379ea"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-xWpHN8pfDL",
    "outputId": "7f6bacd8-d077-43b5-c131-5b081fba24a4"
   },
   "outputs": [],
   "source": [
    "# Running conversion to TFLite command\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJfYMbN6pfDL"
   },
   "outputs": [],
   "source": [
    "# Creating path and file for TFLite model\n",
    "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
    "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating conversion to TFLite command\n",
    "command = \"tflite_convert \\\n",
    "--saved_model_dir={} \\\n",
    "--output_file={} \\\n",
    "--input_shapes=1,300,300,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=FLOAT \\\n",
    "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8GwUeoFpfDL",
    "outputId": "fac43ea4-cc85-471b-a362-e994b06fd583"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nbd7gqHMpfDL",
    "outputId": "7c8fe6d5-2415-4641-8548-39d425c202f7"
   },
   "outputs": [],
   "source": [
    "# Running updated conversion to TFLite command\n",
    "!{command}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3. Training and Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "licenta",
   "language": "python",
   "name": "licenta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
