{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUANWN3rpfC9"
   },
   "source": [
    "# 0. Setup of Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "146BB11JpfDA"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42hJEdo_pfDB"
   },
   "outputs": [],
   "source": [
    "# File name, links that will be used frequently\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet'\n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbPhYVy_pfDB"
   },
   "outputs": [],
   "source": [
    "# Paths that will be used frequently\n",
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow', 'scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow', 'models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace', 'annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace', 'images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace', 'models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace', 'pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NAME),\n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH': os.path.join('Tensorflow', 'workspace', 'models', CUSTOM_MODEL_NAME, 'tfjsexport'),  \n",
    "    'TFLITE_PATH': os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH': os.path.join('Tensorflow', 'protoc'),\n",
    "    'REALTIMEDETECTIONS_PATH': os.path.join('RealTimeDetections')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwhWZMI0pfDC"
   },
   "outputs": [],
   "source": [
    "# Files that will be used frequently\n",
    "files = {\n",
    "    'PIPELINE_CONFIG': os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HR-TfDGrpfDC"
   },
   "outputs": [],
   "source": [
    "# Creating all needed directories\n",
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLU-rs_ipfDE"
   },
   "source": [
    "# 1. Downloading TF Models Pretrained Models from Tensorflow Model Zoo and Installing TFOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow for Windows\n",
    "# https://www.tensorflow.org/install/source_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-Cmz2edpfDE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Installing Wget for windows users\n",
    "if os.name=='nt':\n",
    "    !pip install wget\n",
    "    import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iA1DIq5OpfDE"
   },
   "outputs": [],
   "source": [
    "# Cloning into the Tensorflow repository to get TFOD\n",
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJjMHbnDs3Tv"
   },
   "outputs": [],
   "source": [
    "# Installing Tensorflow Object Detection \n",
    "if os.name=='posix':  \n",
    "    !apt-get install protobuf-compiler\n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "if os.name=='nt':\n",
    "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "    wget.download(url)\n",
    "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    !cd Tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verification script from Tensorflow \n",
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verifying installation for TFOD\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing some other needed dependencies\n",
    "!pip install tensorflow tensorflow-gpu --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tf-models-official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverifying installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "csofht2npfDE",
    "outputId": "ff5471b2-bed2-43f2-959c-327a706527b6"
   },
   "outputs": [],
   "source": [
    "# Downloading and unzipping pretrained model\n",
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5KJTnkfpfDC"
   },
   "source": [
    "# 2. Creating the Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1BVDWo7pfDC"
   },
   "outputs": [],
   "source": [
    "# Creating the Label Map\n",
    "labels = [{'name':'licence', 'id':1}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C88zyVELpfDC"
   },
   "source": [
    "# 3. Creating TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading dataset from\n",
    "# https://www.kaggle.com/datasets/andrewmvd/car-plate-detection?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvf5WccwrFGq",
    "outputId": "49902aeb-0bd7-4298-e1a0-5b4a64eb2064"
   },
   "outputs": [],
   "source": [
    "# If running on colab, run this instruction\n",
    "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
    "if os.path.exists(ARCHIVE_FILES):\n",
    "  !tar -zxvf {ARCHIVE_FILES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloning script to generate TF records\n",
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPFToGZqpfDD",
    "outputId": "0ebb456f-aadc-4a1f-96e6-fbfec1923e1c"
   },
   "outputs": [],
   "source": [
    "# Creating TF records\n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT4QU7pLpfDE"
   },
   "source": [
    "# 4. Copying Model Config to Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOjuTFbwpfDF"
   },
   "outputs": [],
   "source": [
    "# Copying model config file to training folder\n",
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ga8gpNslpfDF"
   },
   "source": [
    "# 5. Updating Config For Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9hRrO_ppfDF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2A0mn4ipfDF"
   },
   "outputs": [],
   "source": [
    "# Getting configs from pipeline config file\n",
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vK5lotDpfDF"
   },
   "outputs": [],
   "source": [
    "# Read contents of pipeline config file\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()  \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rP43Ph0JpfDG"
   },
   "outputs": [],
   "source": [
    "# Update config file for transfer learning\n",
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJvfgwWqpfDG"
   },
   "outputs": [],
   "source": [
    "# Write updated configs to pipeline config file\n",
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zr3ON7xMpfDG"
   },
   "source": [
    "# 6. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-Y2UQmQpfDG"
   },
   "outputs": [],
   "source": [
    "# Training script from TFOD\n",
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMP2XDfQpfDH"
   },
   "outputs": [],
   "source": [
    "# Generating training command\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=10000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4OXXi-ApfDH",
    "outputId": "117a0e83-012b-466e-b7a6-ccaa349ac5ab"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing needed dependency for training\n",
    "!pip install lvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3ZsJR-qpfDH",
    "outputId": "cabec5e1-45e6-4f2f-d9cf-297d9c1d0225"
   },
   "outputs": [],
   "source": [
    "# Running training process\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_YRZu7npfDH"
   },
   "source": [
    "# 7. Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80L7-fdPpfDH"
   },
   "outputs": [],
   "source": [
    "# Generating model evaluation command\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lYsgEPx9pfDH",
    "outputId": "8632d48b-91d2-45d9-bcb8-c1b172bf6eed"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqTV2jGBpfDH"
   },
   "outputs": [],
   "source": [
    "# Running evaluating process\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orvRk02UpfDI"
   },
   "source": [
    "# 8. Loading Trained Model From Checkpoint and Building a Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8TYk4_oIpfDI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing dependency for GPU consumption\n",
    "!pip install GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil\n",
    "\n",
    "# Preventing GPU from complete consumption of resources\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try: \n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
    "    except RunTimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDnQg-cYpfDI"
   },
   "outputs": [],
   "source": [
    "# Loading pipeline config file\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restoring latest checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-11')).expect_partial()\n",
    "\n",
    "\n",
    "# Building a detection model\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    \"\"\"Build detection model function\n",
    "\n",
    "        Parameters:\n",
    "            image ():\n",
    "\n",
    "        Returns:\n",
    "            detections (): \"\"\"\n",
    "    \n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EmsmbBZpfDI"
   },
   "source": [
    "# 9. Detecting plate from an Image, OCR, Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing needed dependencies detection\n",
    "!pip install avro-python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_MKiuZ4pfDI"
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBDbIhNapfDI"
   },
   "outputs": [],
   "source": [
    "# Categories extracted from labelmap\n",
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lx3crOhOzITB"
   },
   "outputs": [],
   "source": [
    "# Image to detect plate number from\n",
    "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'Cars1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "Tpzn1SMry1yK",
    "outputId": "c392a2c5-10fe-4fc4-9998-a1d4c7db2bd3"
   },
   "outputs": [],
   "source": [
    "# Preprocessing image\n",
    "img_orig = cv2.imread(IMAGE_PATH)\n",
    "print('ORIGINAL')\n",
    "plt.imshow(img_orig)\n",
    "plt.show()\n",
    "\n",
    "img_resized = cv2.resize(img_orig, None, fx=1.2, fy=1.2, interpolation=cv2.INTER_CUBIC)\n",
    "print('IMPROVED RESOLUTION')\n",
    "plt.imshow(img_resized)\n",
    "plt.show()\n",
    "\n",
    "img_detailsEnhanced = cv2.detailEnhance(img_resized, sigma_s=10, sigma_r=0.15)\n",
    "print('DETAILS ENHANCED')\n",
    "plt.imshow(img_detailsEnhanced)\n",
    "plt.show()\n",
    "\n",
    "img_BilateralFilterEnhanced = cv2.bilateralFilter(img_detailsEnhanced, 9, 75, 75)\n",
    "print('BILATERAL FILTER ENHANCED')\n",
    "plt.imshow(img_BilateralFilterEnhanced)\n",
    "plt.show()\n",
    "\n",
    "img_BilateralFilterEnhancedGray = cv2.cvtColor(img_BilateralFilterEnhanced, cv2.COLOR_BGR2GRAY)\n",
    "print('BILATERAL GRAY ENHANCED')\n",
    "plt.imshow(img_BilateralFilterEnhancedGray, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "img_threshEnhanced = cv2.threshold(cv2.medianBlur(img_BilateralFilterEnhancedGray, 3), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "print('THRESH 1 ENHANCED')\n",
    "plt.imshow(img_threshEnhanced, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "img_backtorgb = cv2.cvtColor(img_threshEnhanced,cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "image_np = np.array(img_backtorgb)\n",
    "\n",
    "# Detection\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# Detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "# Visualizing detection\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.8,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "print('Detected plate')\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing EasyOCR and needed dependencies\n",
    "!pip install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter OCR function\n",
    "def filter_text(region, ocr_result, region_threshold) -> list:\n",
    "    \"\"\"Filter OCR function\n",
    "\n",
    "        Parameters:\n",
    "            region ():\n",
    "            ocr_resultb ():\n",
    "            region_threshold ():\n",
    "\n",
    "        Returns:\n",
    "            plate (list): \"\"\"\n",
    "    \n",
    "    rectangle_size = region.shape[0]*region.shape[1]\n",
    "    \n",
    "    plate = [] \n",
    "    for result in ocr_result:\n",
    "        length = np.sum(np.subtract(result[0][1], result[0][0]))\n",
    "        height = np.sum(np.subtract(result[0][2], result[0][1]))\n",
    "        \n",
    "        if length*height / rectangle_size > region_threshold:\n",
    "    return plate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR proccess and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholds for detection and OCR filtering\n",
    "detection_threshold = 0.7\n",
    "region_threshold = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR function\n",
    "def ocr_it(image, detections, detection_threshold, region_threshold):\n",
    "    \"\"\"OCR function\n",
    "\n",
    "        Parameters:\n",
    "            image ():\n",
    "            detections ():\n",
    "            detection_threshold ():\n",
    "            region_threshold ():\n",
    "\n",
    "        Returns:\n",
    "            text (): \n",
    "            region (): \"\"\"\n",
    "    \n",
    "    # Scores, boxes and classes above threhold\n",
    "    scores = list(filter(lambda x: x> detection_threshold, detections['detection_scores']))\n",
    "    boxes = detections['detection_boxes'][:len(scores)]\n",
    "    classes = detections['detection_classes'][:len(scores)]\n",
    "    \n",
    "    # Full image dimensions\n",
    "    width = image.shape[1]\n",
    "    height = image.shape[0]\n",
    "    \n",
    "    # Apply ROI filtering and OCR\n",
    "    for idx, box in enumerate(boxes):\n",
    "        roi = box*[height, width, height, width]\n",
    "        region = image[int(roi[0]):int(roi[2]),int(roi[1]):int(roi[3])]\n",
    "        reader = easyocr.Reader(['en'])\n",
    "        ocr_result = reader.readtext(region)\n",
    "        \n",
    "        text = filter_text(region, ocr_result, region_threshold)\n",
    "        \n",
    "        plt.imshow(cv2.cvtColor(region, cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        print(text)\n",
    "        return text, region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import uuid\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving detections\n",
    "def save_results(text, region):\n",
    "    \"\"\"Save results function\n",
    "\n",
    "        Parameters:\n",
    "            text ():\n",
    "            region ():\n",
    "\n",
    "        Returns: N/A\"\"\"\n",
    "    \n",
    "    now = datetime.now()\n",
    "    date_string = now.strftime('%y-%m-%d')\n",
    "    print(date_string)\n",
    "    time_string = now.strftime('%H-%M-%S')\n",
    "    print(time_string)\n",
    "    \n",
    "    folder_path_images = 'RealTimeDetectionsImages\\RealTimeDetections-{}'.format(date_string)\n",
    "    img_name = '{}_{}.jpg'.format(time_string, uuid.uuid1())\n",
    "    forlder_path_csv = 'RealTimeDetections'\n",
    "    csv_filename = 'RealTimeDetections\\RealTimeDetections-{}.csv'.format(date_string)\n",
    "    \n",
    "    if not os.path.exists(folder_path_images):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {folder_path_images}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {folder_path_images}\n",
    "    \n",
    "    if not os.path.exists(forlder_path_csv):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {forlder_path_csv}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {forlder_path_csv}\n",
    "            \n",
    "    cv2.imwrite(os.path.join(folder_path_images, img_name), region)\n",
    "                \n",
    "    with open(csv_filename, mode='a', newline='') as f:\n",
    "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        if text == []:\n",
    "            text = ['unreadable']\n",
    "        csv_writer.writerow([date_string, time_string, img_name, text])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsNAaYAo0WVL"
   },
   "source": [
    "# 10. Real Time Detections from Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "o_grs6OGpfDJ",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Real Time Detections from Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Preprocessing image\n",
    "    img_resized = cv2.resize(frame, None, fx=1.2, fy=1.2, interpolation=cv2.INTER_CUBIC)\n",
    "    img_detailsEnhanced = cv2.detailEnhance(img_resized, sigma_s=10, sigma_r=0.15)\n",
    "    img_BilateralFilterEnhanced = cv2.bilateralFilter(img_detailsEnhanced, 9, 75, 75)\n",
    "    img_BilateralFilterEnhancedGray = cv2.cvtColor(img_BilateralFilterEnhanced, cv2.COLOR_BGR2GRAY)\n",
    "    img_threshEnhanced = cv2.threshold(cv2.medianBlur(img_BilateralFilterEnhancedGray, 3), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "    img_backtorgb = cv2.cvtColor(img_threshEnhanced,cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    image_np = np.array(frame)\n",
    "    image_np_preprocessed = np.array(img_backtorgb)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np_preprocessed, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "    \n",
    "    # Detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.8,\n",
    "                agnostic_mode=False)\n",
    "    \n",
    "    try:\n",
    "        text, region = ocr_it(image_np_with_detections, detections, detection_threshold, region_threshold)\n",
    "        save_results(text, region)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzlM4jt0pfDJ"
   },
   "source": [
    "# 10. Freezing the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4olHB2npfDJ"
   },
   "outputs": [],
   "source": [
    "# Freeze script from TFOD\n",
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AjO93QDpfDJ"
   },
   "outputs": [],
   "source": [
    "# Generating freezing command\n",
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6Lsp3tCpfDJ",
    "outputId": "c3828529-bf06-4df5-d7f3-145890ec3edd"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Sw1ULgHpfDJ",
    "outputId": "6fd441e1-9fc9-4889-d072-3395c21e40b6"
   },
   "outputs": [],
   "source": [
    "# Running freezing process\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTPmdqaXpfDK"
   },
   "source": [
    "# 11. Conversion to TFJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZ6UzY_fpfDK",
    "outputId": "0c84722e-1c2b-4002-d857-80827ade828a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Installing needed package for conversion to TFJS\n",
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0oxbVynHpfDK"
   },
   "outputs": [],
   "source": [
    "# Generating conversion to TFJS command\n",
    "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DB2AGNmJpfDK",
    "outputId": "fbc9f747-f511-47e8-df8f-5ea65cef0374"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7rfT4-hpfDK",
    "outputId": "532707fd-6feb-4bc6-84a3-325b5d16303c"
   },
   "outputs": [],
   "source": [
    "# Running conversion to TFJS command\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtUw73FHpfDK"
   },
   "source": [
    "# 12. Conversion to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XviMtewLpfDK"
   },
   "outputs": [],
   "source": [
    "# TFLite script from TFOD\n",
    "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "us86cjC4pfDL"
   },
   "outputs": [],
   "source": [
    "# Generating conversion to TFLite command\n",
    "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1r5YO3rpfDL",
    "outputId": "5fcdf7a4-eee2-4365-f1ca-1751968379ea"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-xWpHN8pfDL",
    "outputId": "7f6bacd8-d077-43b5-c131-5b081fba24a4"
   },
   "outputs": [],
   "source": [
    "# Running conversion to TFLite command\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJfYMbN6pfDL"
   },
   "outputs": [],
   "source": [
    "# Creating path and file for TFLite model\n",
    "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
    "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating conversion to TFLite command\n",
    "command = \"tflite_convert \\\n",
    "--saved_model_dir={} \\\n",
    "--output_file={} \\\n",
    "--input_shapes=1,300,300,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=FLOAT \\\n",
    "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8GwUeoFpfDL",
    "outputId": "fac43ea4-cc85-471b-a362-e994b06fd583"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nbd7gqHMpfDL",
    "outputId": "7c8fe6d5-2415-4641-8548-39d425c202f7"
   },
   "outputs": [],
   "source": [
    "# Running updated conversion to TFLite command\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NQqZRdA21Uc"
   },
   "source": [
    "# 13. Zipping and Exporting Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Google Colab package\n",
    "!pip install google-colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTVTGCQp2ZJJ"
   },
   "outputs": [],
   "source": [
    "# Zipping checkpoints of model\n",
    "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "whShhB0x3PYJ",
    "outputId": "b773201d-35c9-46a8-b893-4a76bd4d5d97"
   },
   "outputs": [],
   "source": [
    "# Exporting checkpoint to Google Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting and processing data from the CSV detection files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromCsv(elem):\n",
    "    \"\"\"Get data from CSV function\n",
    "\n",
    "        Parameters:\n",
    "            elem ():\n",
    "\n",
    "        Returns: \n",
    "        [listDateNew, listTimeNew, listFileNameNew, listPlateNew] (): \"\"\"\n",
    "    \n",
    "    \n",
    "    dataDate = pd.read_csv(os.path.join('RealTimeDetections\\\\New', elem), header=None, usecols=[0])\n",
    "    dataTime = pd.read_csv(os.path.join('RealTimeDetections\\\\New', elem), header=None, usecols=[1])\n",
    "    dataFileName = pd.read_csv(os.path.join('RealTimeDetections\\\\New', elem), header=None, usecols=[2])\n",
    "    dataPlate = pd.read_csv(os.path.join('RealTimeDetections\\\\New', elem), header=None, usecols=[3])\n",
    "    \n",
    "    listDate = dataDate.values.tolist()\n",
    "    listTime = dataTime.values.tolist()\n",
    "    listFileName = dataFileName.values.tolist()\n",
    "    listPlate = dataPlate.values.tolist()\n",
    "    \n",
    "    listDateNew = [elem[0] for elem in listDate]\n",
    "    listTimeNew = [elem[0] for elem in listTime]\n",
    "    listFileNameNew = [elem[0] for elem in listFileName]\n",
    "    listPlateNew = [elem[0] for elem in listPlate]\n",
    "    \n",
    "    listPlateNewNew = []\n",
    "    for elem in listPlateNew:\n",
    "        elem = elem[2:-2]\n",
    "        listPlateNewNew.append(elem)\n",
    "     \n",
    "    # print(listDateNew)\n",
    "    # print()\n",
    "    # print(listTimeNew)\n",
    "    # print()\n",
    "    # print(listFileNameNew)\n",
    "    # print()\n",
    "    # print(listPlateNewNew)\n",
    "    # print()\n",
    "    # print(\"--------------------------------------------------------\")\n",
    "    \n",
    "    return [listDateNew, listTimeNew, listFileNameNew, listPlateNew]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redundancyFunction(datesToPass, timestampsToPass, filenamesToPass, platesToPass):    \n",
    "    \"\"\"Build detection model function\n",
    "        Parameters:\n",
    "            datesToPass ():\n",
    "            timestampsToPass ():\n",
    "            filenamesToPass ():\n",
    "            platesToPass ():\n",
    "        Returns:\n",
    "            [timestampsValids, datesValids, filenamesValids, platesValids] (): \"\"\"\n",
    "    \n",
    "    datesValids = []\n",
    "    timestampsValids = []\n",
    "    filenamesValids = []\n",
    "    platesValids = []\n",
    "    \n",
    "    for i, timestampi in enumerate(timestampsToPass):\n",
    "        datesValid = []\n",
    "        timestampsValid = []\n",
    "        filenamesValid = []\n",
    "        platesValid = []\n",
    "        onlyOne = True\n",
    "        \n",
    "        timestamp1 = (datetime.strptime(timestampi,\"%H-%M-%S\").time())\n",
    "        \n",
    "        flag = True\n",
    "        if(len(timestampsValids) != 0):\n",
    "            for elem in timestampsValids:\n",
    "                if timestamp1.strftime(\"%H-%M-%S\") in elem:\n",
    "                    flag = False\n",
    "                    break\n",
    "        \n",
    "        if(timestampi != timestampsToPass[-1] and flag == True):\n",
    "            for j, timestampj in enumerate(timestampsToPass[i+1:]):\n",
    "                timestamp2 = (datetime.strptime(timestampj,\"%H-%M-%S\").time())\n",
    "                ##print(f'{timestamp1}, {timestamp2}')\n",
    "                if((timestamp1.hour == timestamp2.hour) and (timestamp1.minute == timestamp2.minute)):\n",
    "                    if(timestamp1.strftime(\"%H-%M-%S\") not in timestampsValid):\n",
    "                        timestampsValid.append(timestamp1.strftime(\"%H-%M-%S\"))\n",
    "                        datesValid.append(datesToPass[i])\n",
    "                        filenamesValid.append(filenamesToPass[i])\n",
    "                        platesValid.append(platesToPass[i])\n",
    "                    if timestamp2 not in timestampsValid:\n",
    "                        timestampsValid.append(timestamp2.strftime(\"%H-%M-%S\"))\n",
    "                        datesValid.append(datesToPass[i+1+j])\n",
    "                        filenamesValid.append(filenamesToPass[i+1+j])\n",
    "                        platesValid.append(platesToPass[i+1+j])\n",
    "                        onlyOne = False\n",
    "                elif(onlyOne == True):\n",
    "                    timestampsValid.append(timestamp1.strftime(\"%H-%M-%S\"))\n",
    "                    datesValid.append(datesToPass[i])\n",
    "                    filenamesValid.append(filenamesToPass[i])\n",
    "                    platesValid.append(platesToPass[i])\n",
    "                    break\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        if(len(timestampsValid) != 0):\n",
    "            timestampsValids.append(timestampsValid)\n",
    "            datesValids.append(datesValid)\n",
    "            filenamesValids.append(filenamesValid)\n",
    "            platesValids.append(platesValid)\n",
    "    \n",
    "    # print(timestampsValids)\n",
    "    # print()\n",
    "    # print(datesValids)\n",
    "    # print()\n",
    "    # print(filenamesValids)\n",
    "    # print()\n",
    "    # print(platesValids)\n",
    "    # print()\n",
    "    \n",
    "    return [timestampsValids, datesValids, filenamesValids, platesValids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processPlate(stringsUnreadable, dates, timestamps, filenames):\n",
    "    \"\"\"Redundancy function\n",
    "\n",
    "        Parameters:\n",
    "            stringsUnreadable ():\n",
    "            dates ():\n",
    "            timestamps ():\n",
    "            filenames ():\n",
    "\n",
    "        Returns: \n",
    "        stringFinal (): \"\"\"\n",
    "    \n",
    "    \n",
    "    print(f'Placute neprocesate:\\n{stringsUnreadable}\\n')\n",
    "    \n",
    "    breakFlag = False\n",
    "    \n",
    "    strings = []\n",
    "    for index, elem in enumerate(stringsUnreadable):\n",
    "        if elem != \"['unreadable']\":\n",
    "            strings.append(elem)\n",
    "    \n",
    "    counts_unreadable = []\n",
    "    for elem in stringsUnreadable:\n",
    "        counts_unreadable.append(stringsUnreadable.count(elem))\n",
    "    ##print(counts_unreadable)\n",
    "    \n",
    "    maximum_unreadable = max(counts_unreadable)\n",
    "    if(maximum_unreadable != \"['unreadable']\"):\n",
    "        maximum_index_unreadable = counts_unreadable.index(maximum_unreadable)\n",
    "        dateKept = dates[maximum_index_unreadable]\n",
    "        timestampKept = timestamps[maximum_index_unreadable]\n",
    "        filenameKept = filenames[maximum_index_unreadable]\n",
    "    else:\n",
    "        maximum_index_unreadable = random.randrange(0, len(count_unreadable))\n",
    "        dateKept = dates[maximum_index_unreadable]\n",
    "        timestampKept = timestamps[maximum_index_unreadable]\n",
    "        filenameKept = filenames[maximum_index_unreadable]\n",
    "    \n",
    "    ##print(f'Numar de placute: {len(strings)}\\n')\n",
    "    ##print(f'Placute:\\n{strings}\\n')\n",
    "\n",
    "    strings_sorted = strings\n",
    "    strings_sorted.sort()\n",
    "    ##print(f'Placute sortate:\\n{strings_sorted}\\n')\n",
    "\n",
    "    strings_unique = set(strings)\n",
    "    strings_unique = list(strings_unique)\n",
    "    ##print(f'Placute fara dubluri:\\n{strings_unique}\\n')\n",
    "\n",
    "    if len(strings_unique) == 0:\n",
    "        breakFlag = True\n",
    "    \n",
    "    if breakFlag == True:\n",
    "        stringFinal = stringsUnreadable[0]\n",
    "        dateKept = dates[0]\n",
    "        timestampKept = timestamps[0]\n",
    "        filenameKept = filenames[0]\n",
    "    \n",
    "    if breakFlag == False:\n",
    "        counts = []\n",
    "        for elem in strings_unique:\n",
    "            counts.append(strings.count(elem))\n",
    "        ##print(f'Numar de aparitii fiecare placuta unica:\\n{counts}\\n')\n",
    "\n",
    "        maximum = max(counts)\n",
    "        maximum_index = counts.index(maximum)\n",
    "        ##print(f'Cel mai mare numar de aparitii: {maximum}')\n",
    "        ##print(f'Se afla la indexul: {maximum_index}\\n')\n",
    "\n",
    "        stringsValues = []\n",
    "        stringsCounts = []\n",
    "        if(counts.count(maximum) == 1):\n",
    "            for index, elem in enumerate(strings_unique):\n",
    "                if (len(elem) == len(strings_unique[maximum_index])):\n",
    "                    stringsValues.append(elem)\n",
    "                    stringsCounts.append(counts[index])\n",
    "                else:\n",
    "                    pass\n",
    "                    ##print(f'{elem} stearsa din detectii!')\n",
    "        elif(counts.count(maximum) == len(strings_unique)):\n",
    "            for index, elem in enumerate(strings_unique):\n",
    "                if (len(elem) == len(strings_unique[0])):\n",
    "                    stringsValues.append(elem)\n",
    "                    stringsCounts.append(counts[index])\n",
    "        else:\n",
    "            for index, elem in enumerate(strings_unique):\n",
    "                if (len(elem) == len(strings_unique[maximum_index])):\n",
    "                    stringsValues.append(elem)\n",
    "                    stringsCounts.append(counts[index])\n",
    "\n",
    "        ##print(f'\\nPlacute luate in considerare:\\n{stringsValues}')\n",
    "        ##print(f'Cu numerele de apartii:\\n{stringsCounts}\\n')\n",
    "\n",
    "        literePosibilePlacuta = []\n",
    "        factoriPlacuta = []\n",
    "        for i in range(0, len(strings_unique[maximum_index])):\n",
    "            literePosibile = []\n",
    "            factori = []\n",
    "            for index, elem in enumerate(stringsValues):\n",
    "                ##print(f'Litera de pe indexul {i} din placuta cu numarul {index} este {elem[i]} si are un factor de {stringsCounts[index]}')\n",
    "                literaPosibila = elem[i]\n",
    "                factor = counts[index]\n",
    "                if literaPosibila not in literePosibile:\n",
    "                    literePosibile.append(literaPosibila)\n",
    "                    factori.append(factor)\n",
    "                else:\n",
    "                    indexLiteraExistenta = literePosibile.index(literaPosibila)\n",
    "                    factori[indexLiteraExistenta] += factor\n",
    "            ##print()\n",
    "            literePosibilePlacuta.append(literePosibile)\n",
    "            factoriPlacuta.append(factori)\n",
    "\n",
    "        for i in range(0, len(strings_unique[maximum_index])):\n",
    "            pass\n",
    "            ##print(f'Pentru caracterul de pe indexul {i} luam in considerare: {literePosibilePlacuta[i]} cu factorii {factoriPlacuta[i]}')\n",
    "        print()\n",
    "\n",
    "        stringFinal = ''\n",
    "        for index, elem in enumerate(literePosibilePlacuta):\n",
    "            if(len(elem) == 1):\n",
    "                ##print(f'Pentru indexul {index} am ales {elem[0]}')\n",
    "                stringFinal = stringFinal + elem[0]\n",
    "            else:\n",
    "                maximum_local = max(factoriPlacuta[index])\n",
    "                maximum_local_index = factoriPlacuta[index].index(maximum_local)\n",
    "                ##print(f'Pentru indexul {index} am ales {elem[maximum_local_index]}')\n",
    "                stringFinal = stringFinal + elem[maximum_local_index]\n",
    "\n",
    "    print(f'\\nPlacuta finala: {stringFinal}')\n",
    "    print(f'\\nPreluata la data de: {dateKept}')\n",
    "    print(f'\\nOra: {timestampKept}')\n",
    "    print(f'\\nFisierul: {filenameKept}')\n",
    "    print('================================')\n",
    "    return [stringFinal, dateKept, timestampKept, filenameKept]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placute neprocesate:\n",
      "[\"['MHIZDE1433']\", \"['MHIZDE1433']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['MHIZDE1433']\n",
      "\n",
      "Preluata la data de: 22-05-25\n",
      "\n",
      "Ora: 17-41-54\n",
      "\n",
      "Fisierul: 17-41-54_d2244524-dc38-11ec-8f03-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['MAIZ DE1433']\", \"['SAv335c0']\", \"['unreadable']\", \"['BLe654BP']\", \"['BLO654BP']\", \"['unreadable']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['BLe654BP']\n",
      "\n",
      "Preluata la data de: 22-05-25\n",
      "\n",
      "Ora: 17-42-23\n",
      "\n",
      "Fisierul: 17-42-23_e384acf8-dc38-11ec-b1d7-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['BOIRU']\", \"['TO1RU']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['BOIRU']\n",
      "\n",
      "Preluata la data de: 22-05-25\n",
      "\n",
      "Ora: 17-43-02\n",
      "\n",
      "Fisierul: 17-43-02_fa7dcc48-dc38-11ec-a797-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['TVvoooo7']\", \"['1Vv00007']\", \"['[Vvoooo7']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['TVvoooo7']\n",
      "\n",
      "Preluata la data de: 22-05-26\n",
      "\n",
      "Ora: 20-54-41\n",
      "\n",
      "Fisierul: 20-54-41_eb3481cf-dd1c-11ec-a384-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['B OIERU']\", \"['8 007 BMW']\", \"['8 007 BMW']\", \"['8 007 BMW']\", \"['B 007 BMW']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['B 007 BMW']\n",
      "\n",
      "Preluata la data de: 22-05-26\n",
      "\n",
      "Ora: 20-55-49\n",
      "\n",
      "Fisierul: 20-55-49_138a8c77-dd1d-11ec-bd7e-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['MHI2DE1433']\", \"['MHIZ DE4433']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['MHI2DE1433']\n",
      "\n",
      "Preluata la data de: 22-05-26\n",
      "\n",
      "Ora: 20-57-44\n",
      "\n",
      "Fisierul: 20-57-44_582ceabc-dd1d-11ec-bd52-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['SA0335C0']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['SA0335C0']\n",
      "\n",
      "Preluata la data de: 22-05-26\n",
      "\n",
      "Ora: 20-58-12\n",
      "\n",
      "Fisierul: 20-58-12_69172a0e-dd1d-11ec-8664-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['Vooodz']\", \"['TVv00007']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['TVv00007']\n",
      "\n",
      "Preluata la data de: 22-05-26\n",
      "\n",
      "Ora: 20-59-51\n",
      "\n",
      "Fisierul: 20-59-51_a3e00a0c-dd1d-11ec-8085-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['T9ooodz']\", \"['unreadable']\", \"['Tvoooo7']\", \"['T900dz']\", \"['BLO654BP']\", \"['BLO654BP']\", \"['BLe654BP']\", \"['BLP654BP']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['BLe654BP']\n",
      "\n",
      "Preluata la data de: 22-05-26\n",
      "\n",
      "Ora: 21-00-51\n",
      "\n",
      "Fisierul: 21-00-51_c7c0f21a-dd1d-11ec-b318-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['BLO654BP']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['BLO654BP']\n",
      "\n",
      "Preluata la data de: 22-05-26\n",
      "\n",
      "Ora: 21-01-02\n",
      "\n",
      "Fisierul: 21-01-02_cdefbc7e-dd1d-11ec-bf71-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['TTERU']\", \"['unreadable']\", \"['B OIERU']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['B OIERU']\n",
      "\n",
      "Preluata la data de: 22-05-26\n",
      "\n",
      "Ora: 21-02-08\n",
      "\n",
      "Fisierul: 21-02-08_f571c386-dd1d-11ec-940b-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['MHIZ DE1433']\", \"['HH12 DE1433']\", \"['MHIZDE1433']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['MHIZ DE1433']\n",
      "\n",
      "Preluata la data de: 22-05-29\n",
      "\n",
      "Ora: 13-19-28\n",
      "\n",
      "Fisierul: 13-19-28_d2ce57b9-df38-11ec-9cec-84a93815fc0b.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['MH12 DE1433']\", \"['MH1Z DE 1433']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['MH1Z DE 1433']\n",
      "\n",
      "Preluata la data de: 22-06-09\n",
      "\n",
      "Ora: 08-51-47\n",
      "\n",
      "Fisierul: 08-51-47_40452de6-e7b8-11ec-806d-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['HHIZ DE1433']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['HHIZ DE1433']\n",
      "\n",
      "Preluata la data de: 22-06-09\n",
      "\n",
      "Ora: 08-52-02\n",
      "\n",
      "Fisierul: 08-52-02_48b13f73-e7b8-11ec-955e-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['0442 DE1432']\", \"['unreadable']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['0442 DE1432']\n",
      "\n",
      "Preluata la data de: 22-06-09\n",
      "\n",
      "Ora: 08-53-57\n",
      "\n",
      "Fisierul: 08-53-57_8daa3413-e7b8-11ec-a61a-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", '[\\'BL\"654BP\\']', \"['unreadable']\", \"['unreadable']\", \"['B Q1ERU']\", \"['B Q1ERU']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['B Q1ERU']\n",
      "\n",
      "Preluata la data de: 22-06-09\n",
      "\n",
      "Ora: 08-54-01\n",
      "\n",
      "Fisierul: 08-54-01_8ff39883-e7b8-11ec-be2d-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['B OERU']\", \"['B OERU']\", \"['unreadable']\", \"['S4v335c0']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['B OERU']\n",
      "\n",
      "Preluata la data de: 22-06-09\n",
      "\n",
      "Ora: 08-55-01\n",
      "\n",
      "Fisierul: 08-55-01_b3bfb4fa-e7b8-11ec-9acc-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['HHIZ DE1433']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['HHIZ DE1433']\n",
      "\n",
      "Preluata la data de: 22-06-12\n",
      "\n",
      "Ora: 02-51-53\n",
      "\n",
      "Fisierul: 02-51-53_784130f6-e9e1-11ec-ae9e-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['SAe335CC']\", \"['Teooodz']\", \"['I900oo7']\", \"['Veooooz']\", \"['Ieoooo7']\", \"['TVooooo7']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['SAe335CC']\n",
      "\n",
      "Preluata la data de: 22-06-12\n",
      "\n",
      "Ora: 02-52-14\n",
      "\n",
      "Fisierul: 02-52-14_84b717fd-e9e1-11ec-80ed-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['BLP65ZBPI']\", \"['BLP65LBP']\", \"['BLO654BP']\", \"['unreadable']\", \"['BLO654BPI']\", \"['unreadable']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['BLO654BPI']\n",
      "\n",
      "Preluata la data de: 22-06-12\n",
      "\n",
      "Ora: 02-53-14\n",
      "\n",
      "Fisierul: 02-53-14_a8a45f8c-e9e1-11ec-af86-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['B OTERU']\", \"['unreadable']\", \"['OIERU']\", \"['unreadable']\", \"['BOERU']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['OIERU']\n",
      "\n",
      "Preluata la data de: 22-06-12\n",
      "\n",
      "Ora: 02-54-14\n",
      "\n",
      "Fisierul: 02-54-14_cc1285cd-e9e1-11ec-9c4a-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\"]\n",
      "\n",
      "\n",
      "Placuta finala: ['unreadable']\n",
      "\n",
      "Preluata la data de: 22-06-12\n",
      "\n",
      "Ora: 03-18-12\n",
      "\n",
      "Fisierul: 03-18-12_2524c1cc-e9e5-11ec-ad83-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['B O1RY']\", \"['B O1Ry']\", \"['GOIHRU']\", \"['B O1ERU']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['B O1RU']\n",
      "\n",
      "Preluata la data de: 22-06-12\n",
      "\n",
      "Ora: 03-24-02\n",
      "\n",
      "Fisierul: 03-24-02_f5d9e77e-e9e5-11ec-bc2d-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['MHIZ DE143']\", \"['HIZ DE1433']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['HIZ DE1433']\n",
      "\n",
      "Preluata la data de: 22-06-12\n",
      "\n",
      "Ora: 13-36-39\n",
      "\n",
      "Fisierul: 13-36-39_8af8b191-ea3b-11ec-ba80-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['BLO654BP']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['BLO654BP']\n",
      "\n",
      "Preluata la data de: 22-06-12\n",
      "\n",
      "Ora: 13-37-59\n",
      "\n",
      "Fisierul: 13-37-59_bac1c907-ea3b-11ec-9258-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['BLP654BP']\", \"['BLP654BP']\", \"['BLO65LBP']\", \"['BLE654BP']\", \"['BLO654BP']\", \"['BLO654BP']\", \"['PROfrl']\", \"['BOIERU']\", \"['B O1ERU']\", \"['BOIERU']\", \"['unreadable']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['PROfrl']\n",
      "\n",
      "Preluata la data de: 22-06-12\n",
      "\n",
      "Ora: 13-38-01\n",
      "\n",
      "Fisierul: 13-38-01_bbea8c9f-ea3b-11ec-b5de-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['HHZ DE1433']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['HHZ DE1433']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-10-31\n",
      "\n",
      "Fisierul: 16-10-31_33e71be3-eb1a-11ec-9f97-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\"]\n",
      "\n",
      "\n",
      "Placuta finala: ['unreadable']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-11-58\n",
      "\n",
      "Fisierul: 16-11-58_68120f6a-eb1a-11ec-83b8-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['unreadable']\", \"['MHIZDE1433']\", \"['unreadable']\", \"['MHIZdE1433']\", \"['NHIZ DE1433']\", \"['unreadable']\", \"['NHIZ DE1433']\", \"['HHIZDE1433']\", \"['NKIzDE1433']\", \"['NHIZDE1433']\", \"['unreadable']\", \"['MHI2 DE1433']\", \"['MHIZDE1433']\", \"['unreadable']\", \"['MHZ DE1433']\", \"['unreadable']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['MHIZDE1433']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-12-06\n",
      "\n",
      "Fisierul: 16-12-06_6c95e7c9-eb1a-11ec-b9c0-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['unreadable']\", \"['335C0']\", \"['SA0335c0']\", \"['unreadable']\", \"['unreadable']\", \"['SA0335c0']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['SA0335c0']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-13-10\n",
      "\n",
      "Fisierul: 16-13-10_92ac7c28-eb1a-11ec-b1c3-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['[oooodz']\", \"['TVoooo7']\", \"['TVoooo7']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['TVoooo7']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-14-50\n",
      "\n",
      "Fisierul: 16-14-50_ce7a0336-eb1a-11ec-8f91-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['BLP654BP']\", \"['BLe654BF']\", \"['BLO65GBP']\", \"['unreadable']\", \"['BLe654BP']\", \"['BLe65GBP']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['BLe654BP']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-15-33\n",
      "\n",
      "Fisierul: 16-15-33_e803e626-eb1a-11ec-8755-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['BLP6SLBPI']\", \"['unreadable']\", \"['BLO654BP']\", \"['unreadable']\", \"['BLO654BP']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['BLO654BP']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-16-03\n",
      "\n",
      "Fisierul: 16-16-03_f9c7fe5a-eb1a-11ec-95d6-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\"]\n",
      "\n",
      "\n",
      "Placuta finala: ['unreadable']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-17-10\n",
      "\n",
      "Fisierul: 16-17-10_21d5e421-eb1b-11ec-8829-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['IB O1ERU']\", \"['unreadable']\", \"['B O1ERU']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['B O1ERU']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-18-22\n",
      "\n",
      "Fisierul: 16-18-22_4cc1e3e5-eb1b-11ec-b051-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\"]\n",
      "\n",
      "\n",
      "Placuta finala: ['unreadable']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-19-01\n",
      "\n",
      "Fisierul: 16-19-01_63b919c7-eb1b-11ec-a208-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\"]\n",
      "\n",
      "\n",
      "Placuta finala: ['unreadable']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-20-03\n",
      "\n",
      "Fisierul: 16-20-03_88a4c348-eb1b-11ec-aff4-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['VL8331 FY']\", \"['unreadable']\", \"['unreadable']\", \"['VL888LEX']\", \"['VL888LEX']\", \"['VLB88LEX']\", \"['VL888LEX']\", \"['VL888LEX']\", \"['VL888LEX']\", \"['unreadable']\", \"['unreadable']\", \"['VL8881 Fv']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['VL888LEX']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-21-00\n",
      "\n",
      "Fisierul: 16-21-00_aaf5fc9d-eb1b-11ec-b27e-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['VL8881 Fv']\", \"['VL8B8LEX']\", \"['unreadable']\", \"['VL8B8LEX']\", \"['VLB88LEX']\", \"['VL888LFY']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['VL888LEX']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-22-09\n",
      "\n",
      "Fisierul: 16-22-09_d43b25fc-eb1b-11ec-9f4c-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['B 123 VUN']\", \"['B 123 VUM']\", \"['B 123 VUM']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['B 123 VUM']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-23-49\n",
      "\n",
      "Fisierul: 16-23-49_0fb8cc70-eb1c-11ec-b536-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['B 123 VUL']\", \"['B 123 VUM']\", \"['B 123 VUM']\", \"['B 123 VUM']\", \"['B 123 VUM']\", \"['B123 VUM']\", \"['unreadable']\", \"['MHIOW']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['B 123 VUM']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-24-30\n",
      "\n",
      "Fisierul: 16-24-30_2808571b-eb1c-11ec-b954-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['MH 1LWOW']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['MHILWOW']\", \"['unreadable']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['MHILWOW']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-25-02\n",
      "\n",
      "Fisierul: 16-25-02_3b507ca2-eb1c-11ec-820c-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['MIOL']\", \"['unreadable']\", \"['unreadable']\", \"['MILWOW']\", \"['unreadable']\", \"['unreadable']\", \"['BO1ERU']\", \"['BOIERU']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['BOIERU']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-26-06\n",
      "\n",
      "Fisierul: 16-26-06_6129d5c9-eb1c-11ec-99af-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['BO1ERU']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['BO1ERU']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-27-05\n",
      "\n",
      "Fisierul: 16-27-05_8485e8a7-eb1c-11ec-8d4d-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "Placuta finala: ['unreadable']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-28-13\n",
      "\n",
      "Fisierul: 16-28-13_acf4d21a-eb1c-11ec-8ae5-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['B147093']\", \"['B147093']\", \"['B1147093']\", \"['B147093']\", \"['B147093']\", \"['R17o=']\", \"['B147093']\", \"['B147093']\", \"['B147093']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['B147093']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-29-08\n",
      "\n",
      "Fisierul: 16-29-08_cda6f7c9-eb1c-11ec-84c7-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['3147093']\", \"['B147093']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['B LOLERR']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['B147093']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-30-43\n",
      "\n",
      "Fisierul: 16-30-43_065a112a-eb1d-11ec-97e2-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['B LOL ERR']\", \"['B LOLERRE']\", \"['unreadable']\", \"['unreadable']\", \"['B LOLERR']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['B LOL ERR']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-31-12\n",
      "\n",
      "Fisierul: 16-31-12_1770a8b1-eb1d-11ec-93ba-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['unreadable']\", \"['NS 7LARA']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['RSL ARO']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['NS 7LARA']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-32-01\n",
      "\n",
      "Fisierul: 16-32-01_34dc3713-eb1d-11ec-9402-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['8 244 ARO']\", \"['B 244 ARO']\", \"['8 244 ARO']\", \"['B 244 ARO']\", \"['unreadable']\", \"['AR 99 KTA']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['B 244 ARO']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-33-00\n",
      "\n",
      "Fisierul: 16-33-00_5818b5e2-eb1d-11ec-a76c-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['AR 99KT']\", \"['AR 99 KTA']\", \"['AR 99KTA']\", \"['AR 99KTA']\", \"['AR 99KTA']\", \"['unreadable']\", \"['AR 99KTA']\", \"['AR 99 KTA']\", \"['AR 99KTA']\", \"['AR 99 KTA']\", \"['AR 99KTA']\", \"['AR 99 KTA']\", \"['15 99KTA']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['AR 99KTA']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-34-07\n",
      "\n",
      "Fisierul: 16-34-07_7fcc5275-eb1d-11ec-a561-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['AR 99KTA']\", \"['AR99 KTA']\", \"['AR 99KTA']\", \"['AR 99 KTA']\", \"['AR 99 KTA']\", \"['AR 99KTA']\", \"['AR 99KTA']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['AR 99KTA']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-35-00\n",
      "\n",
      "Fisierul: 16-35-00_9f7a5508-eb1d-11ec-9b52-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", '[\"CT 26FAN\\'\"]', \"['CT 26FAN']\", \"['CI 26FAN']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: [\"CT 26FAN'\"]\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-36-15\n",
      "\n",
      "Fisierul: 16-36-15_cc172eff-eb1d-11ec-9eeb-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['CT26FAN']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['PHZEBAR']\", \"['unreadable']\", \"['PHZBBAR']\", \"['PHZBAR']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['PHZBBAR']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-37-01\n",
      "\n",
      "Fisierul: 16-37-01_e7f18b99-eb1d-11ec-b834-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['PHZBAR']\", \"['PHZEAR']\", \"['PHZIBAR']\", \"['BC 641E0']\", \"['unreadable']\", \"['BC 64TEC']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['PHZBAR']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-38-00\n",
      "\n",
      "Fisierul: 16-38-00_0af6226f-eb1e-11ec-a8d2-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "Placuta finala: ['unreadable']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-39-14\n",
      "\n",
      "Fisierul: 16-39-14_36a5a0f6-eb1e-11ec-90fb-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "Placuta finala: ['unreadable']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-40-37\n",
      "\n",
      "Fisierul: 16-40-37_68683470-eb1e-11ec-a776-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['unreadable']\", \"['SV 13CBC']\", \"['SV 13CBC']\", \"['SV 13CBC']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['SV 13CBC']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 16-41-13\n",
      "\n",
      "Fisierul: 16-41-13_7da15c1c-eb1e-11ec-8188-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "Placuta finala: ['unreadable']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 18-07-26\n",
      "\n",
      "Fisierul: 18-07-26_898443f4-eb2a-11ec-8478-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['SV 13CBC']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['SV 13CBC']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['SV 13CBC']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 18-08-22\n",
      "\n",
      "Fisierul: 18-08-22_aa9d33a8-eb2a-11ec-a68d-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['SV 13CBC']\", \"['unreadable']\", \"['SV 13CBC]']\", \"['SVBCBC']\", \"['SV 13CBC']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['SV 13CBC']\", \"['unreadable']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['SV 13CBC']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 18-09-02\n",
      "\n",
      "Fisierul: 18-09-02_c266376e-eb2a-11ec-8d2a-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['GR BLOR']\", \"['GR 43LOR']\", \"['unreadable']\", \"['GR 43LOR']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['GR 43LOR']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 18-10-34\n",
      "\n",
      "Fisierul: 18-10-34_f95622cb-eb2a-11ec-ba92-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['BHISIU']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['BH 75YKU']\", \"['BH 75YKU']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['BH 75YKU']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 18-11-10\n",
      "\n",
      "Fisierul: 18-11-10_0ed6bbeb-eb2b-11ec-a7f8-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['unreadable']\", \"['BH 75YKU']\", \"['75YKU']\", \"['unreadable']\", \"['BH 75YKU']\", \"['BH 75YKU']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['BH ZSYKU']\", \"['BH Z5YKU']\", \"['BH 75YKL']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['BH 75YKU']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 18-12-00\n",
      "\n",
      "Fisierul: 18-12-00_2c4a089c-eb2b-11ec-ad8d-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['PH LORST']\", \"['PH GORS']\", \"['PH LORST']\", \"['PH LORST']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['PH LORST']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 18-13-06\n",
      "\n",
      "Fisierul: 18-13-06_53e6c9a4-eb2b-11ec-9d35-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['PH LORST']\", \"['PH LORST']\", \"['PH LORST']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['PH LORST']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 18-14-12\n",
      "\n",
      "Fisierul: 18-14-12_7affa86f-eb2b-11ec-8167-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['D035q1]']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['D035q1]']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 18-15-08\n",
      "\n",
      "Fisierul: 18-15-08_9cd0d18d-eb2b-11ec-a94d-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['DJ 035013']\", \"['DJ 035013']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['DJ35022']\", \"['0035013']\", \"['0J035013']\", \"['DJ 035013']\", \"['DJ035013']\", \"['Dieor']\", \"['DJ035013']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['DJ 035013']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 18-16-26\n",
      "\n",
      "Fisierul: 18-16-26_cb4dd16f-eb2b-11ec-9bea-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['DJ 035013']\", \"['unreadable']\", \"['DJ 035013']\", \"['DJ035013']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['CJIOGRM']\", \"['CJ gOGRM']\", \"['CJgOGRM']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['DJ 035013']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 18-17-08\n",
      "\n",
      "Fisierul: 18-17-08_e3f732ce-eb2b-11ec-86ad-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['CJ 9OGRM']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['CJ 9OGRM']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 18-18-43\n",
      "\n",
      "Fisierul: 18-18-43_1d03596a-eb2c-11ec-bc66-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['AG 76 MSE']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['AG 76 MSE']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 18-19-26\n",
      "\n",
      "Fisierul: 18-19-26_362ff29f-eb2c-11ec-8e26-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['BH 16 RGH']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['BH 16 RGH']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 18-20-37\n",
      "\n",
      "Fisierul: 18-20-37_60dd2abf-eb2c-11ec-be51-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['BH 16RGL']\", \"['unreadable']\", \"['unreadable']\", \"['BH 16 RGH']\", \"['BH 16 RGH']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['BH 16 RGH']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 18-21-03\n",
      "\n",
      "Fisierul: 18-21-03_70485534-eb2c-11ec-9526-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['unreadable']\", \"['BBJLGDV']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['BBJLGDV']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 18-22-04\n",
      "\n",
      "Fisierul: 18-22-04_94b20419-eb2c-11ec-ab52-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['ROAB 77Cnv']\", \"['unreadable']\", \"['AB 74GDv']\", \"['AB 74GDv']\", \"['AB 74GD1']\", \"['unreadable']\", \"['DB073518']\", \"['DB073518']\", \"['DB073518']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['AB 74GDv']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 18-23-50\n",
      "\n",
      "Fisierul: 18-23-50_d3a6db26-eb2c-11ec-8628-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['0B073518']\", \"['DB073518']\", \"['pB073518']\", \"['DB073518']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['DB073518']\", \"['DB073518']\", \"['DB073518']\", \"['DB073518']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['DB073518']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 18-24-05\n",
      "\n",
      "Fisierul: 18-24-05_dc7ed410-eb2c-11ec-b27d-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['DB073518']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['unreadable']\", \"['[DB073518]']\", \"['DB073518]']\", \"['DB073518']\", \"['DB073518']\", \"['DB073518']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['DB073518']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 18-25-16\n",
      "\n",
      "Fisierul: 18-25-16_06c19873-eb2d-11ec-bc7a-28dfeb6a105c.jpg\n",
      "================================\n",
      "Placute neprocesate:\n",
      "[\"['DB073518']\", \"['unreadable']\", \"['unreadable']\"]\n",
      "\n",
      "\n",
      "\n",
      "Placuta finala: ['DB073518']\n",
      "\n",
      "Preluata la data de: 22-06-13\n",
      "\n",
      "Ora: 18-26-06\n",
      "\n",
      "Fisierul: 18-26-06_24c2292d-eb2d-11ec-b59c-28dfeb6a105c.jpg\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "csvfiles = [f for f in listdir('RealTimeDetections\\\\New') if isfile(join('RealTimeDetections\\\\New', f)) and f.endswith('.csv')]\n",
    "# First one doesn't conform to the template\n",
    "#csvfiles = csvfiles[2:]\n",
    "#print(csvfiles)\n",
    "\n",
    "\n",
    "for elem in csvfiles:\n",
    "    csvReturns = []\n",
    "    redReturns = []\n",
    "    finalPlate = ''\n",
    "    \n",
    "    [csvListDateReturn, csvListTimeReturn, csvListFileNameReturn, csvListPlateReturn] = getDataFromCsv(elem)\n",
    "    csvReturns.extend([csvListDateReturn, csvListTimeReturn, csvListFileNameReturn, csvListPlateReturn])\n",
    "    \n",
    "    #print(csvReturns[0])\n",
    "    #print()\n",
    "    #print(csvReturns[1])\n",
    "    #print()\n",
    "    #print(csvReturns[2])\n",
    "    #print()\n",
    "    #print(csvReturns[3])\n",
    "    #print('---------------------------------------')\n",
    "    \n",
    "    [redListDateReturn, redListTimeReturn, redListFileNameReturn, redListPlateReturn] = redundancyFunction(csvReturns[0], csvReturns[1], csvReturns[2], csvReturns[3])\n",
    "    redReturns.extend([redListDateReturn, redListTimeReturn, redListFileNameReturn, redListPlateReturn])\n",
    "    \n",
    "    #print(redReturns[0])\n",
    "    #print()\n",
    "    #print(redReturns[1])\n",
    "    #print()\n",
    "    #print(redReturns[2])\n",
    "    #print()\n",
    "    #print(redReturns[3])\n",
    "    #print('---------------------------------------')\n",
    "    \n",
    "\n",
    "    \n",
    "    for i, platesToProc in enumerate (redReturns[3]):\n",
    "        finalPlate = processPlate(platesToProc, redReturns[1][i], redReturns[0][i], redReturns[2][i])\n",
    "        \n",
    "        f = open(join('RealTimeDetections\\Processed', f'Processed_{finalPlate[1]}.csv'), 'a')\n",
    "\n",
    "        # create the csv writer\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        row = [finalPlate[1], finalPlate[2], finalPlate[3], finalPlate[0]]\n",
    "        # write a row to the csv file\n",
    "        writer.writerow(row)\n",
    "\n",
    "        # close the file\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvProcessedfiles = [f for f in listdir('RealTimeDetections\\\\Processed') if isfile(join('RealTimeDetections\\\\Processed', f)) and f.endswith('.csv')]\n",
    "\n",
    "for elem in csvProcessedfiles:\n",
    "    findIndex = elem.find('.csv')\n",
    "    elemOutput = elem[:findIndex]\n",
    "    elemOutput = elemOutput + \"_NoBlanks.csv\"\n",
    "    \n",
    "    with open(join('RealTimeDetections\\\\Processed', elem), 'r') as input, open(join('RealTimeDetections\\\\Processed\\\\NoBlanks', elemOutput), 'w', newline='') as output:\n",
    "        writer = csv.writer(output)\n",
    "        for row in csv.reader(input):\n",
    "            if any(field.strip() for field in row):\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "  \n",
    "def run1():\n",
    "    import cv2\n",
    "    # Real Time Detections from Webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    while cap.isOpened(): \n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Preprocessing image\n",
    "        img_resized = cv2.resize(frame, None, fx=1.2, fy=1.2, interpolation=cv2.INTER_CUBIC)\n",
    "        img_detailsEnhanced = cv2.detailEnhance(img_resized, sigma_s=10, sigma_r=0.15)\n",
    "        img_BilateralFilterEnhanced = cv2.bilateralFilter(img_detailsEnhanced, 9, 75, 75)\n",
    "        img_BilateralFilterEnhancedGray = cv2.cvtColor(img_BilateralFilterEnhanced, cv2.COLOR_BGR2GRAY)\n",
    "        img_threshEnhanced = cv2.threshold(cv2.medianBlur(img_BilateralFilterEnhancedGray, 3), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "        img_backtorgb = cv2.cvtColor(img_threshEnhanced,cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "        image_np = np.array(frame)\n",
    "        image_np_preprocessed = np.array(img_backtorgb)\n",
    "    \n",
    "        input_tensor = tf.convert_to_tensor(np.expand_dims(image_np_preprocessed, 0), dtype=tf.float32)\n",
    "        detections = detect_fn(input_tensor)\n",
    "    \n",
    "        num_detections = int(detections.pop('num_detections'))\n",
    "        detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "        detections['num_detections'] = num_detections\n",
    "    \n",
    "        # Detection_classes should be ints.\n",
    "        detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "        label_id_offset = 1\n",
    "        image_np_with_detections = image_np.copy()\n",
    "\n",
    "        viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.8,\n",
    "            agnostic_mode=False)\n",
    "    \n",
    "        try:\n",
    "            text, region = ocr_it(image_np_with_detections, detections, detection_threshold, region_threshold)\n",
    "            save_results(text, region)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    \n",
    "def run2():\n",
    "    time.sleep(1)\n",
    "    print(\"I'm the process with id: {}\".format(self.id))\n",
    "\n",
    "# run1()\n",
    "# t1 = Thread(target=run1)\n",
    "# t2 = Thread(target=run2)\n",
    "\n",
    "# t1.start()\n",
    "# t2.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3. Training and Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "licenta",
   "language": "python",
   "name": "licenta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
